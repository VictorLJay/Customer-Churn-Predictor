{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score,confusion_matrix, accuracy_score\n",
    "\n",
    "# ML classifier models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "\n",
    "# model selection (CV)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the DF into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Education_Level_encoded</th>\n",
       "      <th>Income_Category_encoded</th>\n",
       "      <th>Card_Category_encoded</th>\n",
       "      <th>x0_Married</th>\n",
       "      <th>x0_Single</th>\n",
       "      <th>x0_Unknown</th>\n",
       "      <th>x1_Existing Customer</th>\n",
       "      <th>x2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>...</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  ...  \\\n",
       "0                  777                 1.335             1144  ...   \n",
       "1                  864                 1.541             1291  ...   \n",
       "2                    0                 2.594             1887  ...   \n",
       "3                 2517                 1.405             1171  ...   \n",
       "4                    0                 2.175              816  ...   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Education_Level_encoded  \\\n",
       "0                1.625                  0.061                      2.0   \n",
       "1                3.714                  0.105                      4.0   \n",
       "2                2.333                  0.000                      4.0   \n",
       "3                2.333                  0.760                      2.0   \n",
       "4                2.500                  0.000                      1.0   \n",
       "\n",
       "   Income_Category_encoded  Card_Category_encoded  x0_Married  x0_Single  \\\n",
       "0                      3.0                    0.0         1.0        0.0   \n",
       "1                      1.0                    0.0         0.0        1.0   \n",
       "2                      4.0                    0.0         1.0        0.0   \n",
       "3                      1.0                    0.0         0.0        0.0   \n",
       "4                      3.0                    0.0         1.0        0.0   \n",
       "\n",
       "   x0_Unknown  x1_Existing Customer  x2_M  \n",
       "0         0.0                   1.0   1.0  \n",
       "1         0.0                   1.0   0.0  \n",
       "2         0.0                   1.0   1.0  \n",
       "3         1.0                   1.0   0.0  \n",
       "4         0.0                   1.0   1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"../data/bank_processed_data.csv\", index_col=0)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and y\n",
    "X = bank.drop(columns=\"x1_Existing Customer\")\n",
    "y = bank[\"x1_Existing Customer\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column that I want to identify is **x1_Existing Customer**, being **1** if the customer is still a customer, and **0** otherwise. In this case, as it's a True/False decission, the models that fit better for this type of Supervised ML are the Classifiers.\n",
    "\n",
    "I will start checking the different models, without parameter tuning, for identify which are the models that perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the models\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier()\n",
    "gradient = GradientBoostingClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "extra_tree = ExtraTreesClassifier()\n",
    "support_vector = SVC()\n",
    "\n",
    "\n",
    "models = [neigh, tree, RF, adaboost, gradient, extra_tree, support_vector]\n",
    "model_names = [\"KNeighbors\", \"DecisionTree\", \"RandomForest\", \"AdaBoost\", \n",
    "               \"GradientBoost\", \"ExtraTress\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data per each category is not balanced, as customers represent 83.8% of the sample, the accuracy here is not relevant. \n",
    "\n",
    "In this scenario, I will focus more on `recall`, to ensure that the model classifies correctly the labels, and the precision. Mention that, the main focus will be on the label **0.0, as it is the customers that already churned the bank, and we want to focus on that part** to ensure that our model is able to predict possible future cases and act before churn happens.\n",
    "\n",
    "Last, but not least, `macro avg` will also be taken into consideration, as we want to ensure that **0.0** are classified correctly, but we want that the amount of **1.0** are good too. I would have to find the perfect balance between those metrics.\n",
    "\n",
    "*NOTES*\n",
    "\n",
    "The `precision` is the ratio TP / (TP + FP) where TP is the number of true positives and FP the number of false positives. The precision is intuitively **the ability of the classifier not to label as positive a sample that is negative**.\n",
    "\n",
    "The `recall` is the ratio TP / (TP + FN) where TP is the number of true positives and FN the number of false negatives. The recall is intuitively **the ability of the classifier to find all the positive samples**. Note that in binary classification, recall of the positive class is also known as `sensitivity`; recall of the negative class is `specificity`.\n",
    "\n",
    "The most important for this work is to increase the **sensitivity** (to detect all churn cases). Even though the other parameters are very important also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_classifier_model(models):\n",
    "    \"\"\"\n",
    "    Input: Models to test\n",
    "    Output: DF top 3 models\n",
    "    \"\"\"\n",
    "    # first batch of empty lists    \n",
    "    time_to_train = []\n",
    "    accuracy = []\n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_F1 = []\n",
    "    report_dict = []\n",
    "\n",
    "    for model in models:    \n",
    "        start = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # metrics\n",
    "        accuracy_ = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        clasf_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # appending to empty lists\n",
    "        time_to_train.append((time.time() - start))\n",
    "        accuracy.append(round(accuracy_,4))\n",
    "        macro_precision.append(round(precision,4))\n",
    "        macro_recall.append(round(recall,4))\n",
    "        macro_F1.append(round(f1,4))\n",
    "        report_dict.append(clasf_report_dict)\n",
    "    \n",
    "    # second batch\n",
    "    precision_0 = []\n",
    "    recall_0 = []\n",
    "    f1_0 = []\n",
    "    precision_1 = []\n",
    "    recall_1 = []\n",
    "    f1_1 = []\n",
    "\n",
    "    for report in report_dict:\n",
    "        # Info of churn label\n",
    "        precision_0.append(round(report[\"0.0\"][\"precision\"],4))\n",
    "        recall_0.append(round(report[\"0.0\"][\"recall\"],4))\n",
    "        f1_0.append(round(report[\"0.0\"][\"f1-score\"],4))\n",
    "\n",
    "        # Info of current customers\n",
    "        precision_1.append(round(report[\"1.0\"][\"precision\"],4))\n",
    "        recall_1.append(round(report[\"1.0\"][\"recall\"],4))\n",
    "        f1_1.append(round(report[\"1.0\"][\"f1-score\"],4))\n",
    "        \n",
    "    # creating DF\n",
    "    best_models_DF = pd.DataFrame({\"model\":model_names,\n",
    "                                   \"training_time\":time_to_train,\n",
    "                                   \"accuracy\":accuracy,\n",
    "                                   \"precision_macro\":macro_precision,\n",
    "                                   \"recall_macro\":macro_recall,\n",
    "                                   \"f1_macro\":macro_F1,\n",
    "                                   \"precision_0\":precision_0,\n",
    "                                   \"recall_0\":recall_0,\n",
    "                                   \"f1_0\":f1_0,\n",
    "                                   \"precision_1\":precision_1,\n",
    "                                   \"recall_1\":recall_1,\n",
    "                                   \"f1_1\":f1_1\n",
    "                                  })\n",
    "    \n",
    "    # getting top 3 models\n",
    "    top3 = best_models_DF.sort_values(by=[\"f1_macro\"], ascending=False).reset_index(drop=True).iloc[:3]\n",
    "    \n",
    "    return top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>1.475824</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.866706</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9132</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.386940</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  training_time  accuracy  precision_macro  recall_macro  \\\n",
       "0  GradientBoost       1.475824    0.9650           0.9478        0.9194   \n",
       "1   RandomForest       0.866706    0.9630           0.9461        0.9132   \n",
       "2       AdaBoost       0.386940    0.9605           0.9332        0.9180   \n",
       "\n",
       "   f1_macro  precision_0  recall_0    f1_0  precision_1  recall_1    f1_1  \n",
       "0    0.9328       0.9233    0.8523  0.8864       0.9722    0.9865  0.9793  \n",
       "1    0.9287       0.9223    0.8400  0.8792       0.9699    0.9865  0.9781  \n",
       "2    0.9254       0.8939    0.8554  0.8742       0.9726    0.9806  0.9766  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_classifier_model(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three models that does the best selection for the churned customers and also for the actual customers are **GradientBoost**, **AdaBoost** and **RandomForest**.\n",
    "\n",
    "Now that we have in mind which models work best, let's start tuning them for improve their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "#                   \"criterion\":[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "#                   \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#                   \"n_estimators\":randint(low=50, high=300),\n",
    "#                   \"max_depth\":randint(low=2, high=8),\n",
    "#                   \"max_leaf_nodes\":randint(low=5, high=15)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# gradient_search = RandomizedSearchCV(gradient,\n",
    "#                                      gradient_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=StratifiedKFold(),\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the results obtained, I will create a DF for visualize which are the scores for each scoring. After that, I will pick the parameters that performed better for passing it to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_results = pd.DataFrame(gradient_search.cv_results_)\n",
    "\n",
    "# gradient_results = gradient_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                                      \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                                      \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# gradient_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_results[\"params\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we know which are the best parameters to pass to the model, we will create a function for each one of them and then obtain their respective **y_pred**. The **y_value** obtained will be stored in a variable for, later on, build the `classification_report` and `confusion_matrix`.\n",
    "\n",
    "The structure will be the same for future models and variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV\n",
    "    gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "                       \"criterion\":[\"friedman_mse\", \"mse\"],\n",
    "                       \"max_features\":[\"log2\",\"sqrt\"],\n",
    "                       \"n_estimators\":[260, 265, 270, 275, 280],\n",
    "                       \"max_depth\":[3, 4, 5],\n",
    "                       \"max_leaf_nodes\":[10, 12, 14, 16]\n",
    "                      }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_gradient = GridSearchCV(gradient,\n",
    "                                 gradient_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_gradient.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_gradient.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='log2', max_leaf_nodes=14,\n",
       "                           n_estimators=260)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_trainer(X_train, y_train, X_test, loss, criterion, max_features, n_estimators, max_depth, max_leaf_nodes):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the GradientBoostingClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_gradient \n",
    "    best_gradient = GradientBoostingClassifier(loss=loss, criterion=criterion,\n",
    "                                               max_features=max_features, n_estimators=n_estimators,\n",
    "                                               max_depth=max_depth, max_leaf_nodes=max_leaf_nodes\n",
    "                                              )\n",
    "    \n",
    "    # Model fit\n",
    "    best_gradient.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_gradient.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient = gradient_trainer(X_train_scaled,\n",
    "                                   y_train,\n",
    "                                   X_test_scaled,\n",
    "                                   \"deviance\",\n",
    "                                   \"friedman_mse\",\n",
    "                                   \"log2\",\n",
    "                                   265,\n",
    "                                   5,\n",
    "                                   14\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                   \"n_estimators\":randint(low=10, high=200)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# adaboost_search = RandomizedSearchCV(adaboost,\n",
    "#                                      adaboost_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost_results = pd.DataFrame(adaboost_search.cv_results_)\n",
    "\n",
    "# adaboost_results = adaboost_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                                      \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                                      \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# adaboost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost_results[\"params\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV\n",
    "    adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "                       \"n_estimators\":[155, 158, 160, 161, 164]\n",
    "                      }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_adaboost = GridSearchCV(adaboost,\n",
    "                                 adaboost_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_adaboost.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=155)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_trainer(X_train, y_train, X_test, algorithm, n_estimators):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the AdaBoostClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_adaboost \n",
    "    best_adaboost = AdaBoostClassifier(algorithm=algorithm, n_estimators=n_estimators)\n",
    "    \n",
    "    # Model fit\n",
    "    best_adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_adaboost.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost = adaboost_trainer(X_train_scaled,\n",
    "                                   y_train,\n",
    "                                   X_test_scaled,\n",
    "                                   \"SAMME.R\",\n",
    "                                   155\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "#              \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#              \"class_weight\":[\"balanced\", \"balanced_subsample\"],          \n",
    "#              \"n_estimators\":randint(low=10, high=400),\n",
    "#              \"max_depth\":randint(low=2, high=20),\n",
    "#              \"min_samples_split\":randint(low=2, high=40)\n",
    "#             }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# RF_search = RandomizedSearchCV(RF,\n",
    "#                                RF_params,\n",
    "#                                n_iter=10,\n",
    "#                                n_jobs=-1,\n",
    "#                                cv=50,\n",
    "#                                scoring=scorers,\n",
    "#                                refit=False,\n",
    "#                                random_state=42)\n",
    "\n",
    "# RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_results = pd.DataFrame(RF_search.cv_results_)\n",
    "\n",
    "# RF_results = RF_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                          \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                          \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# RF_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_results[\"params\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV    \n",
    "    RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "                 \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "                 \"class_weight\":[\"balanced\", \"balanced_subsample\"],               \n",
    "                 \"n_estimators\":[390, 395, 400, 405],\n",
    "                 \"max_depth\":[8, 10, 12],\n",
    "                 \"min_samples_split\":[16, 18, 20, 22]\n",
    "                }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_RF = GridSearchCV(RF,\n",
    "                                 RF_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_RF.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_RF.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=12, min_samples_split=18, n_estimators=390)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_trainer(X_train, y_train, X_test, class_weight, criterion, max_features, max_depth, min_samples_split, n_estimators):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the RandomForestClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_RF\n",
    "    best_RF = RandomForestClassifier(class_weight=class_weight, criterion=criterion, max_features=max_features,\n",
    "                                     max_depth=max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "    \n",
    "    # Model fit\n",
    "    best_RF.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_RF.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = RF_trainer(X_train_scaled,\n",
    "                       y_train, \n",
    "                       X_test_scaled, \n",
    "                       \"balanced\", \n",
    "                       \"entropy\", \n",
    "                       \"auto\", \n",
    "                       12, \n",
    "                       18, \n",
    "                       390\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_predictions(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Input: Variables for training a model\n",
    "    Output: y_pred for three different models    \n",
    "    \"\"\"\n",
    "    #GradientBoost\n",
    "    gradient.fit(X_train, y_train)\n",
    "    y_pred_initial_gradient = gradient.predict(X_test)\n",
    "    \n",
    "    #AdaBoost\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    y_pred_initial_adaboost = adaboost.predict(X_test)\n",
    "    \n",
    "    # RF\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_pred_initial_RF = RF.predict(X_test)\n",
    "    \n",
    "    return y_pred_initial_gradient, y_pred_initial_adaboost, y_pred_initial_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_initial_gradient, y_pred_initial_adaboost, y_pred_initial_RF = initial_predictions(X_train_scaled, \n",
    "                                                                                          y_train, \n",
    "                                                                                          X_test_scaled\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.923333     0.972190  0.964956     0.947762      0.964353\n",
      "recall       0.852308     0.986479  0.964956     0.919393      0.964956\n",
      "f1-score     0.886400     0.979282  0.964956     0.932841      0.964383\n",
      "support    325.000000  1701.000000  0.964956  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.932692     0.980163  0.972853     0.956428      0.972548\n",
      "recall       0.895385     0.987654  0.972853     0.941519      0.972853\n",
      "f1-score     0.913658     0.983895  0.972853     0.948776      0.972628\n",
      "support    325.000000  1701.000000  0.972853  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893891     0.972595  0.960513     0.933243      0.959969\n",
      "recall       0.855385     0.980600  0.960513     0.917992      0.960513\n",
      "f1-score     0.874214     0.976581  0.960513     0.925397      0.960160\n",
      "support    325.000000  1701.000000  0.960513  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.897196     0.978299  0.965449     0.937748      0.965289\n",
      "recall       0.886154     0.980600  0.965449     0.933377      0.965449\n",
      "f1-score     0.891641     0.979448  0.965449     0.935544      0.965362\n",
      "support    325.000000  1701.000000  0.965449  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.927586     0.967742  0.961994     0.947664      0.961300\n",
      "recall       0.827692     0.987654  0.961994     0.907673      0.961994\n",
      "f1-score     0.874797     0.977597  0.961994     0.926197      0.961106\n",
      "support    325.000000  1701.000000  0.961994  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.852174     0.981559  0.959526     0.916866      0.960803\n",
      "recall       0.904615     0.970018  0.959526     0.937317      0.959526\n",
      "f1-score     0.877612     0.975754  0.959526     0.926683      0.960011\n",
      "support    325.000000  1701.000000  0.959526  2026.000000   2026.000000\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_pred_initial_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing AdaBoost\n",
    "print(f\"AdaBoost\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_pred_initial_adaboost, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_adaboost, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing RandomForest\n",
    "print(f\"RandomForest\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_pred_initial_RF, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_RF, output_dict=True, target_names=['Churn', 'Customer']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the `classification_report`, we will focus on the **Churn** column. On a first view, we can identify that the best models are the `GradientBoost` and `RandomForest`. Let's dive deep and compare each other:\n",
    "1. **`GradientBoost`**: The `precision` is 0.9326, the `recall` is 0.8953, the `f1-score` is 0.9136 and the `accuracy` is 0.9728.\n",
    "2. **`RandomForest`**: The `precision` is 0.8521, the `recall` is 0.9046, the `f1-score` is 0.8776 and the `accuracy` is 0.9595.\n",
    "\n",
    "Although the `recall` is higher on the `RandomForest`, the precision has a big difference compared to the `GradientBoost`. Also, taking into consideration that the `f1-score` will give us a more accurate reference of which model performs better with a more conservative approach, we can ensure that the **`GradientBoost`** is the best model overall.\n",
    "\n",
    "For further testing, we will only focus with that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already did our initial `RandomizedSearchCV` for obtaining the values were we should focus with the `GridSearchCV`, in this case is not neccesary to do that step again.\n",
    "\n",
    "What we will do, is the following:\n",
    "* Split the test size in two different values, **0.1** and **0.3**.\n",
    "* Obtain the best parameters for the gridsearch and see if they are slightly different from the previous model.\n",
    "* Train the models with the new samples.\n",
    "* Compare the new `classification_report` with the previous one and see if there is improvement. **In case that the model improves, for further analysis we will use the best one**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(X, y, test_size = 0.1, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_10 = scaler.fit_transform(X_train_10)\n",
    "X_test_scaled_10 = scaler.transform(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', max_depth=5, max_features='sqrt',\n",
       "                           max_leaf_nodes=16, n_estimators=265)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_10 = gradient_trainer(X_train_scaled_10,\n",
    "                                      y_train_10, \n",
    "                                      X_test_scaled_10, \n",
    "                                      \"deviance\", \n",
    "                                      \"mse\", \n",
    "                                      \"sqrt\", \n",
    "                                      265, \n",
    "                                      5, \n",
    "                                      16\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X, y, test_size = 0.3, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_30 = scaler.fit_transform(X_train_30)\n",
    "X_test_scaled_30 = scaler.transform(X_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='log2', max_leaf_nodes=14,\n",
       "                           n_estimators=270)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_30 = gradient_trainer(X_train_scaled_30,\n",
    "                                      y_train_30,\n",
    "                                      X_test_scaled_30,\n",
    "                                      \"deviance\",\n",
    "                                      \"friedman_mse\",\n",
    "                                      \"log2\",\n",
    "                                      270,\n",
    "                                      5,\n",
    "                                      14\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New sample results VS Previous sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.932692     0.980163  0.972853     0.956428      0.972548\n",
      "recall       0.895385     0.987654  0.972853     0.941519      0.972853\n",
      "f1-score     0.913658     0.983895  0.972853     0.948776      0.972628\n",
      "support    325.000000  1701.000000  0.972853  2026.000000   2026.000000\n",
      "\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.914634    0.984688  0.973346     0.949661      0.973416\n",
      "recall       0.920245    0.983529  0.973346     0.951887      0.973346\n",
      "f1-score     0.917431    0.984108  0.973346     0.950770      0.973379\n",
      "support    163.000000  850.000000  0.973346  1013.000000   1013.000000\n",
      "\n",
      "test_size=0.3:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.944072     0.974537  0.970056     0.959304      0.969645\n",
      "recall       0.864754     0.990200  0.970056     0.927477      0.970056\n",
      "f1-score     0.902674     0.982306  0.970056     0.942490      0.969519\n",
      "support    488.000000  2551.000000  0.970056  3039.000000   3039.000000\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\ntest_size=0.2:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.1:\\n{pd.DataFrame(classification_report(y_test_10, y_pred_gradient_10, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.3:\\n{pd.DataFrame(classification_report(y_test_30, y_pred_gradient_30, output_dict=True, target_names=['Churn', 'Customer']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`test_size` reduced**\n",
    "\n",
    "Looking on the *Churn* customers, when the `test_size` is reduced, the **recall** improves and the **precision** goes worse. This doesn't happen on the *AdaBoost*, that's why I will be focusing on the other models.\n",
    "\n",
    "Looking into *RandomForest* and *GradientBoost* we can conclude that the best model is **GradientBoost**. The reason why is because the `recall` for the churned customers on both models is the same, but the `precision` drops significantly on the *RandomForest*. Also, important to mention that the overall metrics for the *Customers* are better on the *GradientBoost* too.\n",
    "\n",
    "* **`test_size` amplified**\n",
    "\n",
    "On the other hand, when we increase the `test_size`, the `recall` for the *Churn* customers goes down on the three models. Although in some cases the `precision` improves, the overall `f1_score` shows us that the results are worse with that sample, that's why we discard it.\n",
    "\n",
    "* **conclusions**\n",
    "\n",
    "As the results improve with less sample, is better to stay with a **`test_size = 0.1`** rather than a `0.2`.\n",
    "\n",
    "We might consider keep reducing the sample to see if the numbers improve more, but that wouldn't be a good practice as with each sample reduction the variance would increase, causing on overfitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the measures take into consideration the `macro avg` instead of the `weighted avg`, it would be a good idea to see how the models performs with **resampling**. In this case, there will be two kind of resamples:\n",
    "\n",
    "1. **Over Sampling**: Fake data will be created for the train set using the `SMOTE` method, increasing the size of the minority class as maximum as possible.\n",
    "2. **Under Sampling**: Original data will be removed for the train set using `NearMiss` method, reducing the majority class to the same amount as the minority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({1.0: 6799, 0.0: 1302})\n",
      "Resample dataset shape: Counter({0.0: 6799, 1.0: 6799})\n"
     ]
    }
   ],
   "source": [
    "# initializing SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking that the amount is the same for each value\n",
    "\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_smote = scaler.fit_transform(X_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', loss='exponential', max_depth=4,\n",
       "                           max_features='sqrt', max_leaf_nodes=16,\n",
       "                           n_estimators=265)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_smote = gradient_trainer(X_train_scaled_smote,\n",
    "                                         y_train_smote,\n",
    "                                         X_test_scaled,\n",
    "                                         \"exponential\",\n",
    "                                         \"mse\",\n",
    "                                         \"sqrt\",\n",
    "                                         265,\n",
    "                                         4,\n",
    "                                         16\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({1.0: 6799, 0.0: 1302})\n",
      "Resample dataset shape: Counter({0.0: 1302, 1.0: 1302})\n"
     ]
    }
   ],
   "source": [
    "# initializing NearMiss\n",
    "\n",
    "nm = NearMiss()\n",
    "\n",
    "X_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking that the amount is the same for each value\n",
    "\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_train_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_nm = scaler.fit_transform(X_train_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', max_depth=4, max_features='log2',\n",
       "                           max_leaf_nodes=14, n_estimators=280)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_nm, y_train_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_nm = gradient_trainer(X_train_scaled_nm,\n",
    "                                         y_train_nm,\n",
    "                                         X_test_scaled,\n",
    "                                         \"deviance\",\n",
    "                                         \"mse\",\n",
    "                                         \"log2\",\n",
    "                                         280,\n",
    "                                         4,\n",
    "                                         14\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.914634    0.984688  0.973346     0.949661      0.973416\n",
      "recall       0.920245    0.983529  0.973346     0.951887      0.973346\n",
      "f1-score     0.917431    0.984108  0.973346     0.950770      0.973379\n",
      "support    163.000000  850.000000  0.973346  1013.000000   1013.000000\n",
      "\n",
      "Over Sampling:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.229358     1.000000  0.461007     0.614679      0.876378\n",
      "recall       1.000000     0.358025  0.461007     0.679012      0.461007\n",
      "f1-score     0.373134     0.527273  0.461007     0.450204      0.502547\n",
      "support    325.000000  1701.000000  0.461007  2026.000000   2026.000000\n",
      "\n",
      "Under Sampling:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.280799     0.936000   0.64462     0.608400      0.830896\n",
      "recall       0.778462     0.619048   0.64462     0.698755      0.644620\n",
      "f1-score     0.412724     0.745223   0.64462     0.578974      0.691885\n",
      "support    325.000000  1701.000000   0.64462  2026.000000   2026.000000\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(f\"GradientBoost\\ntest_size=0.1:\\n{pd.DataFrame(classification_report(y_test_10, y_pred_gradient_10, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Over Sampling:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient_smote, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Under Sampling:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient_nm, output_dict=True, target_names=['Churn', 'Customer']))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
