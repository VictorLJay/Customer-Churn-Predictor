{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, make_scorer\n",
    "\n",
    "# ML classifier models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# model selection (CV)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the DF into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Education_Level_encoded</th>\n",
       "      <th>Income_Category_encoded</th>\n",
       "      <th>Card_Category_encoded</th>\n",
       "      <th>x0_Married</th>\n",
       "      <th>x0_Single</th>\n",
       "      <th>x0_Unknown</th>\n",
       "      <th>x1_Existing Customer</th>\n",
       "      <th>x2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>...</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  ...  \\\n",
       "0                  777                 1.335             1144  ...   \n",
       "1                  864                 1.541             1291  ...   \n",
       "2                    0                 2.594             1887  ...   \n",
       "3                 2517                 1.405             1171  ...   \n",
       "4                    0                 2.175              816  ...   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Education_Level_encoded  \\\n",
       "0                1.625                  0.061                      2.0   \n",
       "1                3.714                  0.105                      4.0   \n",
       "2                2.333                  0.000                      4.0   \n",
       "3                2.333                  0.760                      2.0   \n",
       "4                2.500                  0.000                      1.0   \n",
       "\n",
       "   Income_Category_encoded  Card_Category_encoded  x0_Married  x0_Single  \\\n",
       "0                      3.0                    0.0         1.0        0.0   \n",
       "1                      1.0                    0.0         0.0        1.0   \n",
       "2                      4.0                    0.0         1.0        0.0   \n",
       "3                      1.0                    0.0         0.0        0.0   \n",
       "4                      3.0                    0.0         1.0        0.0   \n",
       "\n",
       "   x0_Unknown  x1_Existing Customer  x2_M  \n",
       "0         0.0                   1.0   1.0  \n",
       "1         0.0                   1.0   0.0  \n",
       "2         0.0                   1.0   1.0  \n",
       "3         1.0                   1.0   0.0  \n",
       "4         0.0                   1.0   1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"../data/bank_processed_data.csv\", index_col=0)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and y\n",
    "X = bank.drop(columns=\"x1_Existing Customer\")\n",
    "y = bank[\"x1_Existing Customer\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column that I want to identify is **x1_Existing Customer**, being **1** if the customer is still a customer, and **0** otherwise. In this case, as it's a True/False decission, the models that fit better for this type of Supervised ML are the Classifiers.\n",
    "\n",
    "I will start checking the different models, without parameter tuning, for identify which are the models that perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the models\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier()\n",
    "gradient = GradientBoostingClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "extra_tree = ExtraTreesClassifier()\n",
    "support_vector = SVC()\n",
    "\n",
    "\n",
    "models = [neigh, tree, RF, adaboost, gradient, extra_tree, support_vector]\n",
    "model_names = [\"KNeighbors\", \"DecisionTree\", \"RandomForest\", \"AdaBoost\", \n",
    "               \"GradientBoost\", \"ExtraTress\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data per each category is not balanced, as customers represent 83.8% of the sample, the accuracy here is not relevant. \n",
    "\n",
    "In this scenario, I will focus more on *recall*, to ensure that the model classifies correctly the labels, and the precision. Mention that, the main focus will be on the label **0.0**, as it is the customers that already churned the bank, and we want to focus on that part to ensure that our model is able to predict possible future cases and act before churn happens.\n",
    "\n",
    "Last, but not least, *macro avg* will also be taken into consideration, as we want to ensure that **0.0** are classified correctly, but we want that the amount of **1.0** are good too. I would have to find the perfect balance between those metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of KNeighborsClassifier() | Precision 0.86 | Recall 0.73 | F1 0.77:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.49      0.61       327\n",
      "         1.0       0.91      0.98      0.94      1699\n",
      "\n",
      "    accuracy                           0.90      2026\n",
      "   macro avg       0.86      0.73      0.77      2026\n",
      "weighted avg       0.89      0.90      0.89      2026\n",
      "\n",
      "Training time of 0.801854133605957\n",
      "\n",
      "Classification Report of DecisionTreeClassifier() | Precision 0.87 | Recall 0.87 | F1 0.87:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.77      0.78       327\n",
      "         1.0       0.96      0.96      0.96      1699\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.87      0.87      0.87      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "Training time of 0.07579708099365234\n",
      "\n",
      "Classification Report of RandomForestClassifier() | Precision 0.94 | Recall 0.9 | F1 0.92:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.80      0.86       327\n",
      "         1.0       0.96      0.99      0.98      1699\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.94      0.90      0.92      2026\n",
      "weighted avg       0.96      0.96      0.96      2026\n",
      "\n",
      "Training time of 1.1289796829223633\n",
      "\n",
      "Classification Report of AdaBoostClassifier() | Precision 0.92 | Recall 0.9 | F1 0.91:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.82      0.84       327\n",
      "         1.0       0.97      0.98      0.97      1699\n",
      "\n",
      "    accuracy                           0.95      2026\n",
      "   macro avg       0.92      0.90      0.91      2026\n",
      "weighted avg       0.95      0.95      0.95      2026\n",
      "\n",
      "Training time of 0.4936795234680176\n",
      "\n",
      "Classification Report of GradientBoostingClassifier() | Precision 0.95 | Recall 0.91 | F1 0.93:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.88       327\n",
      "         1.0       0.97      0.99      0.98      1699\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.95      0.91      0.93      2026\n",
      "weighted avg       0.96      0.96      0.96      2026\n",
      "\n",
      "Training time of 1.8500525951385498\n",
      "\n",
      "Classification Report of ExtraTreesClassifier() | Precision 0.93 | Recall 0.82 | F1 0.86:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.64      0.76       327\n",
      "         1.0       0.93      0.99      0.96      1699\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.93      0.82      0.86      2026\n",
      "weighted avg       0.93      0.93      0.93      2026\n",
      "\n",
      "Training time of 0.7150859832763672\n",
      "\n",
      "Classification Report of SVC() | Precision 0.9 | Recall 0.82 | F1 0.85:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.65      0.74       327\n",
      "         1.0       0.94      0.98      0.96      1699\n",
      "\n",
      "    accuracy                           0.93      2026\n",
      "   macro avg       0.90      0.82      0.85      2026\n",
      "weighted avg       0.92      0.93      0.92      2026\n",
      "\n",
      "Training time of 0.9644193649291992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_to_train = []\n",
    "macro_precision = []\n",
    "macro_recall = []\n",
    "macro_F1 = []\n",
    "report_dict = []\n",
    "\n",
    "for model in models:    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # metrics\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    clasf_report = classification_report(y_test, y_pred)\n",
    "    clasf_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    print(f\"Classification Report of {model} | Precision {round(precision,2)} | Recall {round(recall,2)} | F1 {round(f1,2)}:\")\n",
    "    print(f\"{clasf_report}\")\n",
    "    print(f\"Training time of {time.time() - start}\\n\")\n",
    "    \n",
    "    # appending to empty lists\n",
    "    time_to_train.append((time.time() - start))\n",
    "    macro_precision.append(round(precision,2))\n",
    "    macro_recall.append(round(recall,2))\n",
    "    macro_F1.append(round(f1,2))\n",
    "    report_dict.append(clasf_report_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_0 = []\n",
    "recall_0 = []\n",
    "f1_0 = []\n",
    "precision_1 = []\n",
    "recall_1 = []\n",
    "f1_1 = []\n",
    "\n",
    "for report in report_dict:\n",
    "    # Info of churn label\n",
    "    precision_0.append(round(report[\"0.0\"][\"precision\"],2))\n",
    "    recall_0.append(round(report[\"0.0\"][\"recall\"],2))\n",
    "    f1_0.append(round(report[\"0.0\"][\"f1-score\"],2))\n",
    "    \n",
    "    # Info of current customers\n",
    "    precision_1.append(round(report[\"1.0\"][\"precision\"],2))\n",
    "    recall_1.append(round(report[\"1.0\"][\"recall\"],2))\n",
    "    f1_1.append(round(report[\"1.0\"][\"f1-score\"],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the information, I will create a DF for better visualization of the different models, beign able to identify which ones will provide best results for identiying churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models_DF = pd.DataFrame({\"model\":model_names,\n",
    "                               \"training_time\":time_to_train,\n",
    "                               \"precision_macro\":macro_precision,\n",
    "                               \"recall_macro\":macro_recall,\n",
    "                               \"f1_macro\":macro_F1,\n",
    "                               \"precision_0\":precision_0,\n",
    "                               \"recall_0\":recall_0,\n",
    "                               \"f1_0\":f1_0,\n",
    "                               \"precision_1\":precision_1,\n",
    "                               \"recall_1\":recall_1,\n",
    "                               \"f1_1\":f1_1\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top3 = best_models_DF.sort_values(by=[\"recall_0\", \"precision_0\", \"recall_macro\"], ascending=False).reset_index(drop=True).iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>1.850053</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.493680</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.128980</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  training_time  precision_macro  recall_macro  f1_macro  \\\n",
       "0  GradientBoost       1.850053             0.95          0.91      0.93   \n",
       "1       AdaBoost       0.493680             0.92          0.90      0.91   \n",
       "2   RandomForest       1.128980             0.94          0.90      0.92   \n",
       "\n",
       "   precision_0  recall_0  f1_0  precision_1  recall_1  f1_1  \n",
       "0         0.94      0.84  0.88         0.97      0.99  0.98  \n",
       "1         0.87      0.82  0.84         0.97      0.98  0.97  \n",
       "2         0.93      0.80  0.86         0.96      0.99  0.98  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three models that does the best selection for the churned customers and also for the actual customers are **GradientBoost**, **AdaBoost** and **RandomForest**.\n",
    "\n",
    "Now that we have in mind which models work best, let's start tuning them for improve their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 811.6379034519196 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "#                   \"criterion\":[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "#                   \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#                   \"n_estimators\":randint(low=50, high=300),\n",
    "#                   \"max_depth\":randint(low=2, high=8),\n",
    "#                   \"max_leaf_nodes\":randint(low=5, high=15)}\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# gradient_search = RandomizedSearchCV(gradient,\n",
    "#                                      gradient_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42)\n",
    "\n",
    "# gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the results obtained, I will create a DF for visualize which are the scores for each scoring. After that, I will pick the parameters that performed better for passing it to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.926291</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846002</td>\n",
       "      <td>6</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.953618</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909780</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929682</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>7</td>\n",
       "      <td>0.784373</td>\n",
       "      <td>8</td>\n",
       "      <td>0.829159</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'mse', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.960300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.927914</td>\n",
       "      <td>3</td>\n",
       "      <td>0.942923</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.962142</td>\n",
       "      <td>2</td>\n",
       "      <td>0.937456</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.962713</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.909723</td>\n",
       "      <td>8</td>\n",
       "      <td>0.790855</td>\n",
       "      <td>7</td>\n",
       "      <td>0.831012</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.877599</td>\n",
       "      <td>10</td>\n",
       "      <td>0.684356</td>\n",
       "      <td>10</td>\n",
       "      <td>0.730526</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'deviance', 'max_...</td>\n",
       "      <td>0.888624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>9</td>\n",
       "      <td>0.791634</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'exponen...</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>5</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912026</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "1  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "2  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "3  {'criterion': 'mse', 'loss': 'exponential', 'm...   \n",
       "4  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "5  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "6  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "7  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "8  {'criterion': 'mae', 'loss': 'deviance', 'max_...   \n",
       "9  {'criterion': 'friedman_mse', 'loss': 'exponen...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.926291                          6   \n",
       "1                   0.953618                          4   \n",
       "2                   0.910651                          7   \n",
       "3                   0.960300                          3   \n",
       "4                   0.962142                          2   \n",
       "5                   0.962713                          1   \n",
       "6                   0.909723                          8   \n",
       "7                   0.877599                         10   \n",
       "8                   0.888624                          9   \n",
       "9                   0.947826                          5   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.846002                       6            0.877009   \n",
       "1                0.909780                       4            0.929682   \n",
       "2                0.784373                       8            0.829159   \n",
       "3                0.927914                       3            0.942923   \n",
       "4                0.937456                       2            0.949083   \n",
       "5                0.938994                       1            0.950104   \n",
       "6                0.790855                       7            0.831012   \n",
       "7                0.684356                      10            0.730526   \n",
       "8                0.747059                       9            0.791634   \n",
       "9                0.884469                       5            0.912026   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   6  \n",
       "1                   4  \n",
       "2                   8  \n",
       "3                   3  \n",
       "4                   2  \n",
       "5                   1  \n",
       "6                   7  \n",
       "7                  10  \n",
       "8                   9  \n",
       "9                   5  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results = pd.DataFrame(gradient_search.cv_results_)\n",
    "\n",
    "gradient_results = gradient_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                     \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                     \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "gradient_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': 14,\n",
       " 'n_estimators': 269}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results[\"params\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.88581919670105 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gradient_params = {\"loss\":[\"deviance\"],\n",
    "                  \"criterion\":[\"friedman_mse\"],\n",
    "                  \"max_features\":[\"log2\"],\n",
    "                  \"n_estimators\":[269],\n",
    "                  \"max_depth\":[4],\n",
    "                  \"max_leaf_nodes\":[14]}\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_gradient_search = GridSearchCV(gradient,\n",
    "                               gradient_params,\n",
    "                               n_jobs=-1,\n",
    "                               cv=50,\n",
    "                               scoring=scorers,\n",
    "                               refit=False)\n",
    "\n",
    "best_gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the gradient with the best parameters, we obtain the training time, which is considerable low. Then, we can start creating the **best_gradient** and predict which is going to be the overall *precision*, *recall* and *F1 Score* for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradient = GradientBoostingClassifier(loss=\"deviance\", criterion=\"friedman_mse\",\n",
    "                                          max_features=\"log2\", n_estimators=269,\n",
    "                                          max_depth=4, max_leaf_nodes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, max_features='log2', max_leaf_nodes=14,\n",
       "                           n_estimators=269)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gradient.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient = best_gradient.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Precision: 0.9744\n",
      "Best Gradient Recall: 0.9871\n",
      "Best Gradient F1 Score: 0.9807\n"
     ]
    }
   ],
   "source": [
    "gradient_precision = round(precision_score(y_test, y_pred_gradient),4)\n",
    "gradient_recall = round(recall_score(y_test, y_pred_gradient), 4)\n",
    "gradient_f1_score = round(f1_score(y_test, y_pred_gradient), 4)\n",
    "\n",
    "print(f\"Best Gradient Precision: {round(precision_score(y_test, y_pred_gradient),4)}\")\n",
    "print(f\"Best Gradient Recall: {round(recall_score(y_test, y_pred_gradient), 4)}\")\n",
    "print(f\"Best Gradient F1 Score: {round(f1_score(y_test, y_pred_gradient), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.541921854019165 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                   \"n_estimators\":randint(low=10, high=200)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# adaboost_search = RandomizedSearchCV(adaboost,\n",
    "#                                      adaboost_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42)\n",
    "\n",
    "# adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 189}</td>\n",
       "      <td>0.936063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 24}</td>\n",
       "      <td>0.906809</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833152</td>\n",
       "      <td>10</td>\n",
       "      <td>0.863271</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 81}</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888706</td>\n",
       "      <td>8</td>\n",
       "      <td>0.907679</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 30}</td>\n",
       "      <td>0.911296</td>\n",
       "      <td>9</td>\n",
       "      <td>0.846614</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873831</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 131}</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 84}</td>\n",
       "      <td>0.928539</td>\n",
       "      <td>8</td>\n",
       "      <td>0.890884</td>\n",
       "      <td>7</td>\n",
       "      <td>0.907993</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 97}</td>\n",
       "      <td>0.933977</td>\n",
       "      <td>5</td>\n",
       "      <td>0.896619</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913639</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 109}</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>4</td>\n",
       "      <td>0.902094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.916889</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 161}</td>\n",
       "      <td>0.934634</td>\n",
       "      <td>3</td>\n",
       "      <td>0.921834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 159}</td>\n",
       "      <td>0.935324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911031</td>\n",
       "      <td>3</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          params  mean_test_precision_score  \\\n",
       "0    {'algorithm': 'SAMME', 'n_estimators': 189}                   0.936063   \n",
       "1     {'algorithm': 'SAMME', 'n_estimators': 24}                   0.906809   \n",
       "2     {'algorithm': 'SAMME', 'n_estimators': 81}                   0.930603   \n",
       "3     {'algorithm': 'SAMME', 'n_estimators': 30}                   0.911296   \n",
       "4    {'algorithm': 'SAMME', 'n_estimators': 131}                   0.933799   \n",
       "5     {'algorithm': 'SAMME', 'n_estimators': 84}                   0.928539   \n",
       "6     {'algorithm': 'SAMME', 'n_estimators': 97}                   0.933977   \n",
       "7    {'algorithm': 'SAMME', 'n_estimators': 109}                   0.934408   \n",
       "8  {'algorithm': 'SAMME.R', 'n_estimators': 161}                   0.934634   \n",
       "9    {'algorithm': 'SAMME', 'n_estimators': 159}                   0.935324   \n",
       "\n",
       "   rank_test_precision_score  mean_test_recall_score  rank_test_recall_score  \\\n",
       "0                          1                0.912258                       2   \n",
       "1                         10                0.833152                      10   \n",
       "2                          7                0.888706                       8   \n",
       "3                          9                0.846614                       9   \n",
       "4                          6                0.905646                       4   \n",
       "5                          8                0.890884                       7   \n",
       "6                          5                0.896619                       6   \n",
       "7                          4                0.902094                       5   \n",
       "8                          3                0.921834                       1   \n",
       "9                          2                0.911031                       3   \n",
       "\n",
       "   mean_test_f1_score  rank_test_f1_score  \n",
       "0            0.923323                   2  \n",
       "1            0.863271                  10  \n",
       "2            0.907679                   8  \n",
       "3            0.873831                   9  \n",
       "4            0.918695                   4  \n",
       "5            0.907993                   7  \n",
       "6            0.913639                   6  \n",
       "7            0.916889                   5  \n",
       "8            0.927895                   1  \n",
       "9            0.922400                   3  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results = pd.DataFrame(adaboost_search.cv_results_)\n",
    "\n",
    "adaboost_results = adaboost_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                     \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                     \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "adaboost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R', 'n_estimators': 161}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results[\"params\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12.782952070236206 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "adaboost_params = {\"algorithm\":[\"SAMME.R\"],\n",
    "                  \"n_estimators\":[161]\n",
    "                  }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_adaboost_search = GridSearchCV(adaboost,\n",
    "                               adaboost_params,\n",
    "                               n_jobs=-1,\n",
    "                               cv=50,\n",
    "                               scoring=scorers,\n",
    "                               refit=False)\n",
    "\n",
    "best_adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost = AdaBoostClassifier(algorithm=\"SAMME.R\", n_estimators=161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=161)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_adaboost.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost = best_adaboost.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Precision: 0.9691\n",
      "Best AdaBoost Recall: 0.9794\n",
      "Best AdaBoost F1 Score: 0.9742\n"
     ]
    }
   ],
   "source": [
    "adaboost_precision = round(precision_score(y_test, y_pred_adaboost),4)\n",
    "adaboost_recall = round(recall_score(y_test, y_pred_adaboost), 4)\n",
    "adaboost_f1_score = round(f1_score(y_test, y_pred_adaboost), 4)\n",
    "\n",
    "print(f\"Best AdaBoost Precision: {round(precision_score(y_test, y_pred_adaboost),4)}\")\n",
    "print(f\"Best AdaBoost Recall: {round(recall_score(y_test, y_pred_adaboost), 4)}\")\n",
    "print(f\"Best AdaBoost F1 Score: {round(f1_score(y_test, y_pred_adaboost), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 178.9842643737793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "#              \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#              \"class_weight\":[\"balanced\", \"balanced_subsample\"],          \n",
    "#              \"n_estimators\":randint(low=10, high=400),\n",
    "#              \"max_depth\":randint(low=2, high=20),\n",
    "#              \"min_samples_split\":randint(low=2, high=40)\n",
    "#             }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# RF_search = RandomizedSearchCV(RF,\n",
    "#                                RF_params,\n",
    "#                                n_iter=10,\n",
    "#                                n_jobs=-1,\n",
    "#                                cv=50,\n",
    "#                                scoring=scorers,\n",
    "#                                refit=False,\n",
    "#                                random_state=42)\n",
    "\n",
    "# RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.937418</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922512</td>\n",
       "      <td>6</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.912491</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922076</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.789057</td>\n",
       "      <td>10</td>\n",
       "      <td>0.884323</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821278</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.869792</td>\n",
       "      <td>8</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893274</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>6</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>3</td>\n",
       "      <td>0.919650</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.948699</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907981</td>\n",
       "      <td>8</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.908830</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>2</td>\n",
       "      <td>0.919668</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.936011</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925385</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.935234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.916906</td>\n",
       "      <td>7</td>\n",
       "      <td>0.924709</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.803499</td>\n",
       "      <td>9</td>\n",
       "      <td>0.892898</td>\n",
       "      <td>9</td>\n",
       "      <td>0.835120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "1  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "2  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "3  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "4  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "5  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "6  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "7  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "8  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "9  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.937418                          2   \n",
       "1                   0.912491                          5   \n",
       "2                   0.789057                         10   \n",
       "3                   0.869792                          8   \n",
       "4                   0.909635                          6   \n",
       "5                   0.948699                          1   \n",
       "6                   0.908830                          7   \n",
       "7                   0.936011                          3   \n",
       "8                   0.935234                          4   \n",
       "9                   0.803499                          9   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.922512                       6            0.928718   \n",
       "1                0.934996                       1            0.922076   \n",
       "2                0.884323                      10            0.821278   \n",
       "3                0.926401                       4            0.893274   \n",
       "4                0.932632                       3            0.919650   \n",
       "5                0.907981                       8            0.925835   \n",
       "6                0.934426                       2            0.919668   \n",
       "7                0.925385                       5            0.929491   \n",
       "8                0.916906                       7            0.924709   \n",
       "9                0.892898                       9            0.835120   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   2  \n",
       "1                   5  \n",
       "2                  10  \n",
       "3                   8  \n",
       "4                   7  \n",
       "5                   3  \n",
       "6                   6  \n",
       "7                   1  \n",
       "8                   4  \n",
       "9                   9  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results = pd.DataFrame(RF_search.cv_results_)\n",
    "\n",
    "RF_results = RF_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                         \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                         \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "RF_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 19,\n",
       " 'n_estimators': 397}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results[\"params\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30.186686992645264 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RF_params = {\"class_weight\":[\"balanced\"],\n",
    "             \"criterion\":[\"gini\"],\n",
    "             \"max_features\":[\"log2\"],\n",
    "             \"max_depth\":[10],\n",
    "             \"min_samples_split\":[19],\n",
    "             \"n_estimators\":[397]\n",
    "            }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_RF_search = GridSearchCV(RF,\n",
    "                              RF_params,\n",
    "                              n_jobs=-1,\n",
    "                              cv=50,\n",
    "                              scoring=scorers,\n",
    "                              refit=False)\n",
    "\n",
    "best_RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF = RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", max_features=\"log2\",\n",
    "                                 max_depth=10, min_samples_split=19, n_estimators=397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
       "                       max_features='log2', min_samples_split=19,\n",
       "                       n_estimators=397)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RF.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = best_RF.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Precision: 0.9792\n",
      "Best RF Recall: 0.9682\n",
      "Best RF F1 Score: 0.9737\n"
     ]
    }
   ],
   "source": [
    "RF_precision = round(precision_score(y_test, y_pred_RF),4)\n",
    "RF_recall = round(recall_score(y_test, y_pred_RF), 4)\n",
    "RF_f1_score = round(f1_score(y_test, y_pred_RF), 4)\n",
    "\n",
    "print(f\"Best RF Precision: {round(precision_score(y_test, y_pred_RF),4)}\")\n",
    "print(f\"Best RF Recall: {round(recall_score(y_test, y_pred_RF), 4)}\")\n",
    "print(f\"Best RF F1 Score: {round(f1_score(y_test, y_pred_RF), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [\"GradientBoost\", \"AdaBoost\", \"RandomForest\"]\n",
    "best_precisions = [gradient_precision, adaboost_precision, RF_precision]\n",
    "best_recalls = [gradient_recall, adaboost_recall, RF_recall]\n",
    "best_f1s = [gradient_f1_score, adaboost_f1_score, RF_f1_score]\n",
    "\n",
    "top_3_models_comparision = pd.DataFrame({\"model\":best_models,\n",
    "                                        \"precision\":best_precisions,\n",
    "                                        \"recall\":best_recalls,\n",
    "                                        \"f1_score\":best_f1s})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
