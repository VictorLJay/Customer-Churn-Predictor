{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score, f1_score, make_scorer, confusion_matrix\n",
    "\n",
    "# ML classifier models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# model selection (CV)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the DF into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Education_Level_encoded</th>\n",
       "      <th>Income_Category_encoded</th>\n",
       "      <th>Card_Category_encoded</th>\n",
       "      <th>x0_Married</th>\n",
       "      <th>x0_Single</th>\n",
       "      <th>x0_Unknown</th>\n",
       "      <th>x1_Existing Customer</th>\n",
       "      <th>x2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>...</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  ...  \\\n",
       "0                  777                 1.335             1144  ...   \n",
       "1                  864                 1.541             1291  ...   \n",
       "2                    0                 2.594             1887  ...   \n",
       "3                 2517                 1.405             1171  ...   \n",
       "4                    0                 2.175              816  ...   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Education_Level_encoded  \\\n",
       "0                1.625                  0.061                      2.0   \n",
       "1                3.714                  0.105                      4.0   \n",
       "2                2.333                  0.000                      4.0   \n",
       "3                2.333                  0.760                      2.0   \n",
       "4                2.500                  0.000                      1.0   \n",
       "\n",
       "   Income_Category_encoded  Card_Category_encoded  x0_Married  x0_Single  \\\n",
       "0                      3.0                    0.0         1.0        0.0   \n",
       "1                      1.0                    0.0         0.0        1.0   \n",
       "2                      4.0                    0.0         1.0        0.0   \n",
       "3                      1.0                    0.0         0.0        0.0   \n",
       "4                      3.0                    0.0         1.0        0.0   \n",
       "\n",
       "   x0_Unknown  x1_Existing Customer  x2_M  \n",
       "0         0.0                   1.0   1.0  \n",
       "1         0.0                   1.0   0.0  \n",
       "2         0.0                   1.0   1.0  \n",
       "3         1.0                   1.0   0.0  \n",
       "4         0.0                   1.0   1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"../data/bank_processed_data.csv\", index_col=0)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and y\n",
    "X = bank.drop(columns=\"x1_Existing Customer\")\n",
    "y = bank[\"x1_Existing Customer\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column that I want to identify is **x1_Existing Customer**, being **1** if the customer is still a customer, and **0** otherwise. In this case, as it's a True/False decission, the models that fit better for this type of Supervised ML are the Classifiers.\n",
    "\n",
    "I will start checking the different models, without parameter tuning, for identify which are the models that perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the models\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier()\n",
    "gradient = GradientBoostingClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "extra_tree = ExtraTreesClassifier()\n",
    "support_vector = SVC(class_weight=\"balanced\", probability=True)\n",
    "\n",
    "\n",
    "models = [neigh, tree, RF, adaboost, gradient, extra_tree, support_vector]\n",
    "model_names = [\"KNeighbors\", \"DecisionTree\", \"RandomForest\", \"AdaBoost\", \n",
    "               \"GradientBoost\", \"ExtraTress\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data per each category is not balanced, as customers represent 83.8% of the sample, the accuracy here is not relevant. \n",
    "\n",
    "In this scenario, I will focus more on *recall*, to ensure that the model classifies correctly the labels, and the precision. Mention that, the main focus will be on the label **0.0**, as it is the customers that already churned the bank, and we want to focus on that part to ensure that our model is able to predict possible future cases and act before churn happens.\n",
    "\n",
    "Last, but not least, *macro avg* will also be taken into consideration, as we want to ensure that **0.0** are classified correctly, but we want that the amount of **1.0** are good too. I would have to find the perfect balance between those metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of KNeighborsClassifier() | Precision 0.86 | Recall 0.76 | F1 0.79:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.79      0.54      0.64       325\n",
      "    Customer       0.92      0.97      0.94      1701\n",
      "\n",
      "    accuracy                           0.90      2026\n",
      "   macro avg       0.86      0.76      0.79      2026\n",
      "weighted avg       0.90      0.90      0.90      2026\n",
      "\n",
      "Training time of 0.6211016178131104\n",
      "\n",
      "Classification Report of DecisionTreeClassifier() | Precision 0.88 | Recall 0.89 | F1 0.88:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.79      0.82      0.80       325\n",
      "    Customer       0.97      0.96      0.96      1701\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.88      0.89      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "Training time of 0.06283164024353027\n",
      "\n",
      "Classification Report of RandomForestClassifier() | Precision 0.95 | Recall 0.92 | F1 0.93:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.92      0.85      0.88       325\n",
      "    Customer       0.97      0.99      0.98      1701\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.95      0.92      0.93      2026\n",
      "weighted avg       0.96      0.96      0.96      2026\n",
      "\n",
      "Training time of 0.8237969875335693\n",
      "\n",
      "Classification Report of AdaBoostClassifier() | Precision 0.93 | Recall 0.92 | F1 0.93:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.89      0.86      0.87       325\n",
      "    Customer       0.97      0.98      0.98      1701\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.93      0.92      0.93      2026\n",
      "weighted avg       0.96      0.96      0.96      2026\n",
      "\n",
      "Training time of 0.41190218925476074\n",
      "\n",
      "Classification Report of GradientBoostingClassifier() | Precision 0.95 | Recall 0.92 | F1 0.93:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.92      0.85      0.89       325\n",
      "    Customer       0.97      0.99      0.98      1701\n",
      "\n",
      "    accuracy                           0.96      2026\n",
      "   macro avg       0.95      0.92      0.93      2026\n",
      "weighted avg       0.96      0.96      0.96      2026\n",
      "\n",
      "Training time of 1.4381487369537354\n",
      "\n",
      "Classification Report of ExtraTreesClassifier() | Precision 0.93 | Recall 0.85 | F1 0.88:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.92      0.70      0.80       325\n",
      "    Customer       0.95      0.99      0.97      1701\n",
      "\n",
      "    accuracy                           0.94      2026\n",
      "   macro avg       0.93      0.85      0.88      2026\n",
      "weighted avg       0.94      0.94      0.94      2026\n",
      "\n",
      "Training time of 0.538560152053833\n",
      "\n",
      "Classification Report of SVC(class_weight='balanced', probability=True) | Precision 0.83 | Recall 0.91 | F1 0.86:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Churn       0.68      0.91      0.78       325\n",
      "    Customer       0.98      0.92      0.95      1701\n",
      "\n",
      "    accuracy                           0.92      2026\n",
      "   macro avg       0.83      0.91      0.86      2026\n",
      "weighted avg       0.93      0.92      0.92      2026\n",
      "\n",
      "Training time of 5.2549426555633545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_to_train = []\n",
    "macro_precision = []\n",
    "macro_recall = []\n",
    "macro_F1 = []\n",
    "report_dict = []\n",
    "\n",
    "for model in models:    \n",
    "    start = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # metrics\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    clasf_report = classification_report(y_test, y_pred, target_names=[\"Churn\", \"Customer\"])\n",
    "    clasf_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    print(f\"Classification Report of {model} | Precision {round(precision,2)} | Recall {round(recall,2)} | F1 {round(f1,2)}:\")\n",
    "    print(f\"{clasf_report}\")\n",
    "    print(f\"Training time of {time.time() - start}\\n\")\n",
    "    \n",
    "    # appending to empty lists\n",
    "    time_to_train.append((time.time() - start))\n",
    "    macro_precision.append(round(precision,2))\n",
    "    macro_recall.append(round(recall,2))\n",
    "    macro_F1.append(round(f1,2))\n",
    "    report_dict.append(clasf_report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*IMPORTANT*\n",
    "\n",
    "The `precision` is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively **the ability of the classifier not to label as positive a sample that is negative**.\n",
    "\n",
    "The `recall` is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively **the ability of the classifier to find all the positive samples**. Note that in binary classification, recall of the positive class is also known as `sensitivity`; recall of the negative class is `specificity`.\n",
    "\n",
    "The most important for this work is to increase the **sensitivity** (to detect all churn cases). Even though the other parameters are very important also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_0 = []\n",
    "recall_0 = []\n",
    "f1_0 = []\n",
    "precision_1 = []\n",
    "recall_1 = []\n",
    "f1_1 = []\n",
    "\n",
    "for report in report_dict:\n",
    "    # Info of churn label\n",
    "    precision_0.append(round(report[\"0.0\"][\"precision\"],2))\n",
    "    recall_0.append(round(report[\"0.0\"][\"recall\"],2))\n",
    "    f1_0.append(round(report[\"0.0\"][\"f1-score\"],2))\n",
    "    \n",
    "    # Info of current customers\n",
    "    precision_1.append(round(report[\"1.0\"][\"precision\"],2))\n",
    "    recall_1.append(round(report[\"1.0\"][\"recall\"],2))\n",
    "    f1_1.append(round(report[\"1.0\"][\"f1-score\"],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the information, I will create a DF for better visualization of the different models, beign able to identify which ones will provide best results for identiying churned customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models_DF = pd.DataFrame({\"model\":model_names,\n",
    "                               \"training_time\":time_to_train,\n",
    "                               \"precision_macro\":macro_precision,\n",
    "                               \"recall_macro\":macro_recall,\n",
    "                               \"f1_macro\":macro_F1,\n",
    "                               \"precision_0\":precision_0,\n",
    "                               \"recall_0\":recall_0,\n",
    "                               \"f1_0\":f1_0,\n",
    "                               \"precision_1\":precision_1,\n",
    "                               \"recall_1\":recall_1,\n",
    "                               \"f1_1\":f1_1\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>1.438149</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.823797</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.411902</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  training_time  precision_macro  recall_macro  f1_macro  \\\n",
       "0  GradientBoost       1.438149             0.95          0.92      0.93   \n",
       "1   RandomForest       0.823797             0.95          0.92      0.93   \n",
       "2       AdaBoost       0.411902             0.93          0.92      0.93   \n",
       "\n",
       "   precision_0  recall_0  f1_0  precision_1  recall_1  f1_1  \n",
       "0         0.92      0.85  0.89         0.97      0.99  0.98  \n",
       "1         0.92      0.85  0.88         0.97      0.99  0.98  \n",
       "2         0.89      0.86  0.87         0.97      0.98  0.98  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3 = best_models_DF.sort_values(by=[\"f1_0\"], ascending=False).reset_index(drop=True).iloc[:3]\n",
    "top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_time</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>1.438178</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.839755</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.407914</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.058816</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>5.158185</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTress</td>\n",
       "      <td>0.529571</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.646728</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  training_time  precision_macro  recall_macro  f1_macro  \\\n",
       "0  GradientBoost       1.438178             0.95          0.91      0.93   \n",
       "1   RandomForest       0.839755             0.94          0.89      0.91   \n",
       "2       AdaBoost       0.407914             0.92          0.90      0.91   \n",
       "3   DecisionTree       0.058816             0.86          0.86      0.86   \n",
       "4            SVC       5.158185             0.83          0.91      0.86   \n",
       "5     ExtraTress       0.529571             0.92          0.82      0.86   \n",
       "6     KNeighbors       0.646728             0.86          0.73      0.77   \n",
       "\n",
       "   precision_0  recall_0  f1_0  precision_1  recall_1  f1_1  \n",
       "0         0.94      0.84  0.89         0.97      0.99  0.98  \n",
       "1         0.92      0.80  0.85         0.96      0.99  0.97  \n",
       "2         0.87      0.82  0.84         0.97      0.98  0.97  \n",
       "3         0.77      0.77  0.77         0.96      0.96  0.96  \n",
       "4         0.68      0.89  0.77         0.98      0.92  0.95  \n",
       "5         0.91      0.64  0.75         0.93      0.99  0.96  \n",
       "6         0.81      0.49  0.61         0.91      0.98  0.94  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ver con guillem\n",
    "best_models_DF.sort_values(by=[\"f1_0\"], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three models that does the best selection for the churned customers and also for the actual customers are **GradientBoost**, **AdaBoost** and **RandomForest**.\n",
    "\n",
    "Now that we have in mind which models work best, let's start tuning them for improve their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 811.6379034519196 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "#                   \"criterion\":[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "#                   \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#                   \"n_estimators\":randint(low=50, high=300),\n",
    "#                   \"max_depth\":randint(low=2, high=8),\n",
    "#                   \"max_leaf_nodes\":randint(low=5, high=15)}\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# gradient_search = RandomizedSearchCV(gradient,\n",
    "#                                      gradient_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the results obtained, I will create a DF for visualize which are the scores for each scoring. After that, I will pick the parameters that performed better for passing it to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.926291</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846002</td>\n",
       "      <td>6</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.953618</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909780</td>\n",
       "      <td>4</td>\n",
       "      <td>0.929682</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.910651</td>\n",
       "      <td>7</td>\n",
       "      <td>0.784373</td>\n",
       "      <td>8</td>\n",
       "      <td>0.829159</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'mse', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.960300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.927914</td>\n",
       "      <td>3</td>\n",
       "      <td>0.942923</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.962142</td>\n",
       "      <td>2</td>\n",
       "      <td>0.937456</td>\n",
       "      <td>2</td>\n",
       "      <td>0.949083</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.962713</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938994</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.909723</td>\n",
       "      <td>8</td>\n",
       "      <td>0.790855</td>\n",
       "      <td>7</td>\n",
       "      <td>0.831012</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.877599</td>\n",
       "      <td>10</td>\n",
       "      <td>0.684356</td>\n",
       "      <td>10</td>\n",
       "      <td>0.730526</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'deviance', 'max_...</td>\n",
       "      <td>0.888624</td>\n",
       "      <td>9</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>9</td>\n",
       "      <td>0.791634</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'exponen...</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>5</td>\n",
       "      <td>0.884469</td>\n",
       "      <td>5</td>\n",
       "      <td>0.912026</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "1  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "2  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "3  {'criterion': 'mse', 'loss': 'exponential', 'm...   \n",
       "4  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "5  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "6  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "7  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "8  {'criterion': 'mae', 'loss': 'deviance', 'max_...   \n",
       "9  {'criterion': 'friedman_mse', 'loss': 'exponen...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.926291                          6   \n",
       "1                   0.953618                          4   \n",
       "2                   0.910651                          7   \n",
       "3                   0.960300                          3   \n",
       "4                   0.962142                          2   \n",
       "5                   0.962713                          1   \n",
       "6                   0.909723                          8   \n",
       "7                   0.877599                         10   \n",
       "8                   0.888624                          9   \n",
       "9                   0.947826                          5   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.846002                       6            0.877009   \n",
       "1                0.909780                       4            0.929682   \n",
       "2                0.784373                       8            0.829159   \n",
       "3                0.927914                       3            0.942923   \n",
       "4                0.937456                       2            0.949083   \n",
       "5                0.938994                       1            0.950104   \n",
       "6                0.790855                       7            0.831012   \n",
       "7                0.684356                      10            0.730526   \n",
       "8                0.747059                       9            0.791634   \n",
       "9                0.884469                       5            0.912026   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   6  \n",
       "1                   4  \n",
       "2                   8  \n",
       "3                   3  \n",
       "4                   2  \n",
       "5                   1  \n",
       "6                   7  \n",
       "7                  10  \n",
       "8                   9  \n",
       "9                   5  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results = pd.DataFrame(gradient_search.cv_results_)\n",
    "\n",
    "gradient_results = gradient_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                     \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                     \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "gradient_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'log2',\n",
       " 'max_leaf_nodes': 14,\n",
       " 'n_estimators': 269}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results[\"params\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.260923147201538 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gradient_params = {\"loss\":[\"deviance\"],\n",
    "                  \"criterion\":[\"friedman_mse\"],\n",
    "                  \"max_features\":[\"log2\"],\n",
    "                  \"n_estimators\":[269],\n",
    "                  \"max_depth\":[4],\n",
    "                  \"max_leaf_nodes\":[14]}\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_gradient_search = GridSearchCV(gradient,\n",
    "                               gradient_params,\n",
    "                               n_jobs=-1,\n",
    "                               cv=50,\n",
    "                               scoring=scorers,\n",
    "                               refit=False)\n",
    "\n",
    "best_gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the gradient with the best parameters, we obtain the training time, which is considerable low. Then, we can start creating the **best_gradient** and predict which is going to be the overall *precision*, *recall* and *F1 Score* for the model.\n",
    "\n",
    "This structure will be the same for the following models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradient = GradientBoostingClassifier(loss=\"deviance\", criterion=\"friedman_mse\",\n",
    "                                          max_features=\"log2\", n_estimators=269,\n",
    "                                          max_depth=4, max_leaf_nodes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, max_features='log2', max_leaf_nodes=14,\n",
       "                           n_estimators=269)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gradient.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient = best_gradient.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.541921854019165 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                   \"n_estimators\":randint(low=10, high=200)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# adaboost_search = RandomizedSearchCV(adaboost,\n",
    "#                                      adaboost_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 189}</td>\n",
       "      <td>0.936063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.912258</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923323</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 24}</td>\n",
       "      <td>0.906809</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833152</td>\n",
       "      <td>10</td>\n",
       "      <td>0.863271</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 81}</td>\n",
       "      <td>0.930603</td>\n",
       "      <td>7</td>\n",
       "      <td>0.888706</td>\n",
       "      <td>8</td>\n",
       "      <td>0.907679</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 30}</td>\n",
       "      <td>0.911296</td>\n",
       "      <td>9</td>\n",
       "      <td>0.846614</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873831</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 131}</td>\n",
       "      <td>0.933799</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905646</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 84}</td>\n",
       "      <td>0.928539</td>\n",
       "      <td>8</td>\n",
       "      <td>0.890884</td>\n",
       "      <td>7</td>\n",
       "      <td>0.907993</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 97}</td>\n",
       "      <td>0.933977</td>\n",
       "      <td>5</td>\n",
       "      <td>0.896619</td>\n",
       "      <td>6</td>\n",
       "      <td>0.913639</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 109}</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>4</td>\n",
       "      <td>0.902094</td>\n",
       "      <td>5</td>\n",
       "      <td>0.916889</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 161}</td>\n",
       "      <td>0.934634</td>\n",
       "      <td>3</td>\n",
       "      <td>0.921834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 159}</td>\n",
       "      <td>0.935324</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911031</td>\n",
       "      <td>3</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          params  mean_test_precision_score  \\\n",
       "0    {'algorithm': 'SAMME', 'n_estimators': 189}                   0.936063   \n",
       "1     {'algorithm': 'SAMME', 'n_estimators': 24}                   0.906809   \n",
       "2     {'algorithm': 'SAMME', 'n_estimators': 81}                   0.930603   \n",
       "3     {'algorithm': 'SAMME', 'n_estimators': 30}                   0.911296   \n",
       "4    {'algorithm': 'SAMME', 'n_estimators': 131}                   0.933799   \n",
       "5     {'algorithm': 'SAMME', 'n_estimators': 84}                   0.928539   \n",
       "6     {'algorithm': 'SAMME', 'n_estimators': 97}                   0.933977   \n",
       "7    {'algorithm': 'SAMME', 'n_estimators': 109}                   0.934408   \n",
       "8  {'algorithm': 'SAMME.R', 'n_estimators': 161}                   0.934634   \n",
       "9    {'algorithm': 'SAMME', 'n_estimators': 159}                   0.935324   \n",
       "\n",
       "   rank_test_precision_score  mean_test_recall_score  rank_test_recall_score  \\\n",
       "0                          1                0.912258                       2   \n",
       "1                         10                0.833152                      10   \n",
       "2                          7                0.888706                       8   \n",
       "3                          9                0.846614                       9   \n",
       "4                          6                0.905646                       4   \n",
       "5                          8                0.890884                       7   \n",
       "6                          5                0.896619                       6   \n",
       "7                          4                0.902094                       5   \n",
       "8                          3                0.921834                       1   \n",
       "9                          2                0.911031                       3   \n",
       "\n",
       "   mean_test_f1_score  rank_test_f1_score  \n",
       "0            0.923323                   2  \n",
       "1            0.863271                  10  \n",
       "2            0.907679                   8  \n",
       "3            0.873831                   9  \n",
       "4            0.918695                   4  \n",
       "5            0.907993                   7  \n",
       "6            0.913639                   6  \n",
       "7            0.916889                   5  \n",
       "8            0.927895                   1  \n",
       "9            0.922400                   3  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results = pd.DataFrame(adaboost_search.cv_results_)\n",
    "\n",
    "adaboost_results = adaboost_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                     \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                     \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "adaboost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R', 'n_estimators': 161}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results[\"params\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.742919921875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "adaboost_params = {\"algorithm\":[\"SAMME.R\"],\n",
    "                  \"n_estimators\":[161]\n",
    "                  }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_adaboost_search = GridSearchCV(adaboost,\n",
    "                               adaboost_params,\n",
    "                               n_jobs=-1,\n",
    "                               cv=50,\n",
    "                               scoring=scorers,\n",
    "                               refit=False)\n",
    "\n",
    "best_adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost = AdaBoostClassifier(algorithm=\"SAMME.R\", n_estimators=161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=161)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_adaboost.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost = best_adaboost.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 178.9842643737793 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "#              \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#              \"class_weight\":[\"balanced\", \"balanced_subsample\"],          \n",
    "#              \"n_estimators\":randint(low=10, high=400),\n",
    "#              \"max_depth\":randint(low=2, high=20),\n",
    "#              \"min_samples_split\":randint(low=2, high=40)\n",
    "#             }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# RF_search = RandomizedSearchCV(RF,\n",
    "#                                RF_params,\n",
    "#                                n_iter=10,\n",
    "#                                n_jobs=-1,\n",
    "#                                cv=50,\n",
    "#                                scoring=scorers,\n",
    "#                                refit=False,\n",
    "#                                random_state=42)\n",
    "\n",
    "# RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.937418</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922512</td>\n",
       "      <td>6</td>\n",
       "      <td>0.928718</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.912491</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922076</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.789057</td>\n",
       "      <td>10</td>\n",
       "      <td>0.884323</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821278</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.869792</td>\n",
       "      <td>8</td>\n",
       "      <td>0.926401</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893274</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>6</td>\n",
       "      <td>0.932632</td>\n",
       "      <td>3</td>\n",
       "      <td>0.919650</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.948699</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907981</td>\n",
       "      <td>8</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.908830</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>2</td>\n",
       "      <td>0.919668</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.936011</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925385</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.935234</td>\n",
       "      <td>4</td>\n",
       "      <td>0.916906</td>\n",
       "      <td>7</td>\n",
       "      <td>0.924709</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.803499</td>\n",
       "      <td>9</td>\n",
       "      <td>0.892898</td>\n",
       "      <td>9</td>\n",
       "      <td>0.835120</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "1  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "2  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "3  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "4  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "5  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "6  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "7  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "8  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "9  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.937418                          2   \n",
       "1                   0.912491                          5   \n",
       "2                   0.789057                         10   \n",
       "3                   0.869792                          8   \n",
       "4                   0.909635                          6   \n",
       "5                   0.948699                          1   \n",
       "6                   0.908830                          7   \n",
       "7                   0.936011                          3   \n",
       "8                   0.935234                          4   \n",
       "9                   0.803499                          9   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.922512                       6            0.928718   \n",
       "1                0.934996                       1            0.922076   \n",
       "2                0.884323                      10            0.821278   \n",
       "3                0.926401                       4            0.893274   \n",
       "4                0.932632                       3            0.919650   \n",
       "5                0.907981                       8            0.925835   \n",
       "6                0.934426                       2            0.919668   \n",
       "7                0.925385                       5            0.929491   \n",
       "8                0.916906                       7            0.924709   \n",
       "9                0.892898                       9            0.835120   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   2  \n",
       "1                   5  \n",
       "2                  10  \n",
       "3                   8  \n",
       "4                   7  \n",
       "5                   3  \n",
       "6                   6  \n",
       "7                   1  \n",
       "8                   4  \n",
       "9                   9  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results = pd.DataFrame(RF_search.cv_results_)\n",
    "\n",
    "RF_results = RF_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                         \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                         \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "RF_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 19,\n",
       " 'n_estimators': 397}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results[\"params\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 30.310616731643677 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RF_params = {\"class_weight\":[\"balanced\"],\n",
    "             \"criterion\":[\"gini\"],\n",
    "             \"max_features\":[\"log2\"],\n",
    "             \"max_depth\":[10],\n",
    "             \"min_samples_split\":[19],\n",
    "             \"n_estimators\":[397]\n",
    "            }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_RF_search = GridSearchCV(RF,\n",
    "                              RF_params,\n",
    "                              n_jobs=-1,\n",
    "                              cv=50,\n",
    "                              scoring=scorers,\n",
    "                              refit=False)\n",
    "\n",
    "best_RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF = RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", max_features=\"log2\",\n",
    "                                 max_depth=10, min_samples_split=19, n_estimators=397)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
       "                       max_features='log2', min_samples_split=19,\n",
       "                       n_estimators=397)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RF.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = best_RF.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing initial results of the models\n",
    "\n",
    "# GradientBoost\n",
    "gradient.fit(X_train_scaled, y_train)\n",
    "y_first_pred_gradient = gradient.predict(X_test_scaled)\n",
    "\n",
    "#AdaBoost\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "y_first_pred_adaboost = adaboost.predict(X_test_scaled)\n",
    "\n",
    "# RF\n",
    "RF.fit(X_train_scaled, y_train)\n",
    "y_first_pred_RF = RF.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.923333     0.972190  0.964956     0.947762      0.964353\n",
      "recall       0.852308     0.986479  0.964956     0.919393      0.964956\n",
      "f1-score     0.886400     0.979282  0.964956     0.932841      0.964383\n",
      "support    325.000000  1701.000000  0.964956  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.935897     0.980747   0.97384     0.958322      0.973552\n",
      "recall       0.898462     0.988242   0.97384     0.943352      0.973840\n",
      "f1-score     0.916797     0.984480   0.97384     0.950639      0.973623\n",
      "support    325.000000  1701.000000   0.97384  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893891     0.972595  0.960513     0.933243      0.959969\n",
      "recall       0.855385     0.980600  0.960513     0.917992      0.960513\n",
      "f1-score     0.874214     0.976581  0.960513     0.925397      0.960160\n",
      "support    325.000000  1701.000000  0.960513  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893750     0.977140  0.963968     0.935445      0.963763\n",
      "recall       0.880000     0.980012  0.963968     0.930006      0.963968\n",
      "f1-score     0.886822     0.978574  0.963968     0.932698      0.963855\n",
      "support    325.000000  1701.000000  0.963968  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.919192     0.969925  0.962488     0.944558      0.961787\n",
      "recall       0.840000     0.985891  0.962488     0.912945      0.962488\n",
      "f1-score     0.877814     0.977843  0.962488     0.927828      0.961796\n",
      "support    325.000000  1701.000000  0.962488  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.827778     0.983794  0.956071     0.905786      0.958766\n",
      "recall       0.916923     0.963551  0.956071     0.940237      0.956071\n",
      "f1-score     0.870073     0.973567  0.956071     0.921820      0.956965\n",
      "support    325.000000  1701.000000  0.956071  2026.000000   2026.000000\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_first_pred_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing AdaBoost\n",
    "print(f\"AdaBoost\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_first_pred_adaboost, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_adaboost, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing RandomForest\n",
    "print(f\"RandomForest\\nInitial:\\n{pd.DataFrame(classification_report(y_test, y_first_pred_RF, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"Modified:\\n{pd.DataFrame(classification_report(y_test, y_pred_RF, output_dict=True, target_names=['Churn', 'Customer']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model between **GradientBoost** (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scenario will be with the same methods, as they were the best. The structure will be the following one:\n",
    "* RandomizedSearchCV for finding the best parameters. In the case the parameters are the same than with the original test_size, this cell will be removed.\n",
    "* Obtain the best parameters of RandomizedSearchCV (in case they are different).\n",
    "* Run the GridSearchCV.\n",
    "* Find the prediction for the different models / tests, doing a later comparision with the original test_size sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(X, y, test_size = 0.1, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler_10 = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled_10 = scaler_10.fit_transform(X_train_10)\n",
    "X_test_scaled_10 = scaler_10.transform(X_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17.027616024017334 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gradient_params_10 = {\"loss\":[\"deviance\"],\n",
    "                      \"criterion\":[\"friedman_mse\"],\n",
    "                      \"max_features\":[\"log2\"],\n",
    "                      \"n_estimators\":[269],\n",
    "                      \"max_depth\":[4],\n",
    "                      \"max_leaf_nodes\":[14]}\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_gradient_search_10 = GridSearchCV(gradient,\n",
    "                                       gradient_params_10,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=50,\n",
    "                                       scoring=scorers,\n",
    "                                       refit=False\n",
    "                                      )\n",
    "\n",
    "best_gradient_search_10.fit(X_train_scaled_10, y_train_10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradient_10 = GradientBoostingClassifier(loss=\"deviance\", criterion=\"friedman_mse\",\n",
    "                                              max_features=\"log2\", n_estimators=269,\n",
    "                                              max_depth=4, max_leaf_nodes=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, max_features='log2', max_leaf_nodes=14,\n",
       "                           n_estimators=269)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gradient_10.fit(X_train_scaled_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient_10 = best_gradient_10.predict(X_test_scaled_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 15.418502807617188 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "adaboost_params_10 = {\"algorithm\":[\"SAMME.R\"],\n",
    "                      \"n_estimators\":[161]\n",
    "                     }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_adaboost_search_10 = GridSearchCV(adaboost,\n",
    "                                       adaboost_params_10,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=50,\n",
    "                                       scoring=scorers,\n",
    "                                       refit=False\n",
    "                                      )\n",
    "\n",
    "best_adaboost_search_10.fit(X_train_scaled_10, y_train_10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost_10 = AdaBoostClassifier(algorithm=\"SAMME.R\", n_estimators=161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=161)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_adaboost_10.fit(X_train_scaled_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost_10 = best_adaboost_10.predict(X_test_scaled_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 199.81752181053162 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RF_params_10 = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "                \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "                \"class_weight\":[\"balanced\", \"balanced_subsample\"],\n",
    "                \"n_estimators\":randint(low=10, high=400),\n",
    "                \"max_depth\":randint(low=2, high=20),\n",
    "                \"min_samples_split\":randint(low=2, high=40)\n",
    "               }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "RF_search_10 = RandomizedSearchCV(RF,\n",
    "                                  RF_params_10,\n",
    "                                  n_iter=10,\n",
    "                                  n_jobs=-1,\n",
    "                                  cv=50,\n",
    "                                  scoring=scorers,\n",
    "                                  refit=False,\n",
    "                                  random_state=42\n",
    "                                 )\n",
    "\n",
    "RF_search_10.fit(X_train_scaled_10, y_train_10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.935569</td>\n",
       "      <td>3</td>\n",
       "      <td>0.924724</td>\n",
       "      <td>7</td>\n",
       "      <td>0.929239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.913592</td>\n",
       "      <td>5</td>\n",
       "      <td>0.938146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924556</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.793462</td>\n",
       "      <td>10</td>\n",
       "      <td>0.888467</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825799</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.871615</td>\n",
       "      <td>8</td>\n",
       "      <td>0.928083</td>\n",
       "      <td>4</td>\n",
       "      <td>0.895344</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.909588</td>\n",
       "      <td>6</td>\n",
       "      <td>0.937760</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921974</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.949398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909672</td>\n",
       "      <td>8</td>\n",
       "      <td>0.927001</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.905827</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934247</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.934053</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926703</td>\n",
       "      <td>5</td>\n",
       "      <td>0.929573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.935842</td>\n",
       "      <td>2</td>\n",
       "      <td>0.925161</td>\n",
       "      <td>6</td>\n",
       "      <td>0.929427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'class_weight': 'balanced_subsample', 'criter...</td>\n",
       "      <td>0.802038</td>\n",
       "      <td>9</td>\n",
       "      <td>0.892698</td>\n",
       "      <td>9</td>\n",
       "      <td>0.833891</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "1  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "2  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "3  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "4  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "5  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "6  {'class_weight': 'balanced', 'criterion': 'gin...   \n",
       "7  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "8  {'class_weight': 'balanced', 'criterion': 'ent...   \n",
       "9  {'class_weight': 'balanced_subsample', 'criter...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.935569                          3   \n",
       "1                   0.913592                          5   \n",
       "2                   0.793462                         10   \n",
       "3                   0.871615                          8   \n",
       "4                   0.909588                          6   \n",
       "5                   0.949398                          1   \n",
       "6                   0.905827                          7   \n",
       "7                   0.934053                          4   \n",
       "8                   0.935842                          2   \n",
       "9                   0.802038                          9   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.924724                       7            0.929239   \n",
       "1                0.938146                       1            0.924556   \n",
       "2                0.888467                      10            0.825799   \n",
       "3                0.928083                       4            0.895344   \n",
       "4                0.937760                       2            0.921974   \n",
       "5                0.909672                       8            0.927001   \n",
       "6                0.934247                       3            0.918355   \n",
       "7                0.926703                       5            0.929573   \n",
       "8                0.925161                       6            0.929427   \n",
       "9                0.892698                       9            0.833891   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   3  \n",
       "1                   5  \n",
       "2                  10  \n",
       "3                   8  \n",
       "4                   6  \n",
       "5                   4  \n",
       "6                   7  \n",
       "7                   1  \n",
       "8                   2  \n",
       "9                   9  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results_10 = pd.DataFrame(RF_search_10.cv_results_)\n",
    "\n",
    "RF_results_10 = RF_results_10[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                               \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                               \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "RF_results_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 12,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_split': 25,\n",
       " 'n_estimators': 382}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_results_10[\"params\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 31.965221881866455 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RF_params_10 = {\"class_weight\":[\"balanced\"],\n",
    "                \"criterion\":[\"gini\"],\n",
    "                \"max_features\":[\"log2\"],\n",
    "                \"max_depth\":[12],\n",
    "                \"min_samples_split\":[25],\n",
    "                \"n_estimators\":[382]\n",
    "               }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_RF_search_10 = GridSearchCV(RF,\n",
    "                                 RF_params_10,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=50,\n",
    "                                 scoring=scorers,\n",
    "                                 refit=False\n",
    "                                )\n",
    "\n",
    "best_RF_search_10.fit(X_train_scaled_10, y_train_10)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF_10 = RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", max_features=\"log2\",\n",
    "                                 max_depth=12, min_samples_split=25, n_estimators=382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=12,\n",
       "                       max_features='log2', min_samples_split=25,\n",
       "                       n_estimators=382)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RF_10.fit(X_train_scaled_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF_10 = best_RF_10.predict(X_test_scaled_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X, y, test_size = 0.3, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler_30 = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled_30 = scaler_10.fit_transform(X_train_30)\n",
    "X_test_scaled_30 = scaler_10.transform(X_test_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 643.497720003128 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# gradient_params_30 = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "#                       \"criterion\":[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "#                       \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#                       \"n_estimators\":randint(low=50, high=300),\n",
    "#                       \"max_depth\":randint(low=2, high=8),\n",
    "#                       \"max_leaf_nodes\":randint(low=5, high=15)\n",
    "#                      }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# gradient_search_30 = RandomizedSearchCV(gradient,\n",
    "#                                         gradient_params_30,\n",
    "#                                         n_iter=10,\n",
    "#                                         n_jobs=-1,\n",
    "#                                         cv=10,\n",
    "#                                         scoring=scorers,\n",
    "#                                         refit=False,\n",
    "#                                         random_state=42\n",
    "#                                        )\n",
    "\n",
    "# gradient_search_30.fit(X_train_scaled_30, y_train_30)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.932549</td>\n",
       "      <td>6</td>\n",
       "      <td>0.857462</td>\n",
       "      <td>6</td>\n",
       "      <td>0.889038</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.951894</td>\n",
       "      <td>4</td>\n",
       "      <td>0.901801</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924365</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.921782</td>\n",
       "      <td>7</td>\n",
       "      <td>0.803202</td>\n",
       "      <td>7</td>\n",
       "      <td>0.846937</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'criterion': 'mse', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.958854</td>\n",
       "      <td>3</td>\n",
       "      <td>0.923660</td>\n",
       "      <td>3</td>\n",
       "      <td>0.940043</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.960722</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933591</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'devianc...</td>\n",
       "      <td>0.961395</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931212</td>\n",
       "      <td>2</td>\n",
       "      <td>0.945293</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.919618</td>\n",
       "      <td>8</td>\n",
       "      <td>0.801238</td>\n",
       "      <td>8</td>\n",
       "      <td>0.842993</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'exponential', 'm...</td>\n",
       "      <td>0.875599</td>\n",
       "      <td>10</td>\n",
       "      <td>0.680450</td>\n",
       "      <td>10</td>\n",
       "      <td>0.726741</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'criterion': 'mae', 'loss': 'deviance', 'max_...</td>\n",
       "      <td>0.893381</td>\n",
       "      <td>9</td>\n",
       "      <td>0.747646</td>\n",
       "      <td>9</td>\n",
       "      <td>0.794207</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'criterion': 'friedman_mse', 'loss': 'exponen...</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>5</td>\n",
       "      <td>0.882930</td>\n",
       "      <td>5</td>\n",
       "      <td>0.910884</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  \\\n",
       "0  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "1  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "2  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "3  {'criterion': 'mse', 'loss': 'exponential', 'm...   \n",
       "4  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "5  {'criterion': 'friedman_mse', 'loss': 'devianc...   \n",
       "6  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "7  {'criterion': 'mae', 'loss': 'exponential', 'm...   \n",
       "8  {'criterion': 'mae', 'loss': 'deviance', 'max_...   \n",
       "9  {'criterion': 'friedman_mse', 'loss': 'exponen...   \n",
       "\n",
       "   mean_test_precision_score  rank_test_precision_score  \\\n",
       "0                   0.932549                          6   \n",
       "1                   0.951894                          4   \n",
       "2                   0.921782                          7   \n",
       "3                   0.958854                          3   \n",
       "4                   0.960722                          2   \n",
       "5                   0.961395                          1   \n",
       "6                   0.919618                          8   \n",
       "7                   0.875599                         10   \n",
       "8                   0.893381                          9   \n",
       "9                   0.947090                          5   \n",
       "\n",
       "   mean_test_recall_score  rank_test_recall_score  mean_test_f1_score  \\\n",
       "0                0.857462                       6            0.889038   \n",
       "1                0.901801                       4            0.924365   \n",
       "2                0.803202                       7            0.846937   \n",
       "3                0.923660                       3            0.940043   \n",
       "4                0.933591                       1            0.946251   \n",
       "5                0.931212                       2            0.945293   \n",
       "6                0.801238                       8            0.842993   \n",
       "7                0.680450                      10            0.726741   \n",
       "8                0.747646                       9            0.794207   \n",
       "9                0.882930                       5            0.910884   \n",
       "\n",
       "   rank_test_f1_score  \n",
       "0                   6  \n",
       "1                   4  \n",
       "2                   7  \n",
       "3                   3  \n",
       "4                   1  \n",
       "5                   2  \n",
       "6                   8  \n",
       "7                  10  \n",
       "8                   9  \n",
       "9                   5  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results_30 = pd.DataFrame(gradient_search_30.cv_results_)\n",
    "\n",
    "gradient_results_30 = gradient_results_30[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                           \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                           \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "gradient_results_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': 10,\n",
       " 'n_estimators': 285}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_results_30[\"params\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12.058336734771729 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "gradient_params_30 = {\"loss\":[\"deviance\"],\n",
    "                      \"criterion\":[\"friedman_mse\"],\n",
    "                      \"max_features\":[\"sqrt\"],\n",
    "                      \"n_estimators\":[285],\n",
    "                      \"max_depth\":[5],\n",
    "                      \"max_leaf_nodes\":[10]}\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_gradient_search_30 = GridSearchCV(gradient,\n",
    "                                       gradient_params_30,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=50,\n",
    "                                       scoring=scorers,\n",
    "                                       refit=False\n",
    "                                      )\n",
    "\n",
    "best_gradient_search_30.fit(X_train_scaled_30, y_train_30)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gradient_30 = GradientBoostingClassifier(loss=\"deviance\", criterion=\"friedman_mse\",\n",
    "                                              max_features=\"sqrt\", n_estimators=285,\n",
    "                                              max_depth=5, max_leaf_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='sqrt', max_leaf_nodes=10,\n",
       "                           n_estimators=285)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gradient_30.fit(X_train_scaled_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient_30 = best_gradient_30.predict(X_test_scaled_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.467572689056396 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# adaboost_params_30 = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                       \"n_estimators\":randint(low=10, high=200)\n",
    "#                      }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# adaboost_search_30 = RandomizedSearchCV(adaboost,\n",
    "#                                         adaboost_params_30,\n",
    "#                                         n_iter=10,\n",
    "#                                         n_jobs=-1,\n",
    "#                                         cv=10,\n",
    "#                                         scoring=scorers,\n",
    "#                                         refit=False,\n",
    "#                                         random_state=42\n",
    "#                                        )\n",
    "\n",
    "# adaboost_search_30.fit(X_train_scaled_30, y_train_30)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_precision_score</th>\n",
       "      <th>rank_test_precision_score</th>\n",
       "      <th>mean_test_recall_score</th>\n",
       "      <th>rank_test_recall_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>rank_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 189}</td>\n",
       "      <td>0.941839</td>\n",
       "      <td>1</td>\n",
       "      <td>0.912465</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 24}</td>\n",
       "      <td>0.904759</td>\n",
       "      <td>10</td>\n",
       "      <td>0.832266</td>\n",
       "      <td>10</td>\n",
       "      <td>0.861997</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 81}</td>\n",
       "      <td>0.933070</td>\n",
       "      <td>7</td>\n",
       "      <td>0.895373</td>\n",
       "      <td>7</td>\n",
       "      <td>0.912438</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 30}</td>\n",
       "      <td>0.913258</td>\n",
       "      <td>9</td>\n",
       "      <td>0.845387</td>\n",
       "      <td>9</td>\n",
       "      <td>0.874004</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 131}</td>\n",
       "      <td>0.937733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.905016</td>\n",
       "      <td>4</td>\n",
       "      <td>0.920090</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 84}</td>\n",
       "      <td>0.933742</td>\n",
       "      <td>5</td>\n",
       "      <td>0.891751</td>\n",
       "      <td>8</td>\n",
       "      <td>0.910690</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 97}</td>\n",
       "      <td>0.933657</td>\n",
       "      <td>6</td>\n",
       "      <td>0.899683</td>\n",
       "      <td>6</td>\n",
       "      <td>0.915225</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 109}</td>\n",
       "      <td>0.934770</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900725</td>\n",
       "      <td>5</td>\n",
       "      <td>0.916334</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'algorithm': 'SAMME.R', 'n_estimators': 161}</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>8</td>\n",
       "      <td>0.917057</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923947</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 159}</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>3</td>\n",
       "      <td>0.905743</td>\n",
       "      <td>3</td>\n",
       "      <td>0.919298</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          params  mean_test_precision_score  \\\n",
       "0    {'algorithm': 'SAMME', 'n_estimators': 189}                   0.941839   \n",
       "1     {'algorithm': 'SAMME', 'n_estimators': 24}                   0.904759   \n",
       "2     {'algorithm': 'SAMME', 'n_estimators': 81}                   0.933070   \n",
       "3     {'algorithm': 'SAMME', 'n_estimators': 30}                   0.913258   \n",
       "4    {'algorithm': 'SAMME', 'n_estimators': 131}                   0.937733   \n",
       "5     {'algorithm': 'SAMME', 'n_estimators': 84}                   0.933742   \n",
       "6     {'algorithm': 'SAMME', 'n_estimators': 97}                   0.933657   \n",
       "7    {'algorithm': 'SAMME', 'n_estimators': 109}                   0.934770   \n",
       "8  {'algorithm': 'SAMME.R', 'n_estimators': 161}                   0.931817   \n",
       "9    {'algorithm': 'SAMME', 'n_estimators': 159}                   0.934959   \n",
       "\n",
       "   rank_test_precision_score  mean_test_recall_score  rank_test_recall_score  \\\n",
       "0                          1                0.912465                       2   \n",
       "1                         10                0.832266                      10   \n",
       "2                          7                0.895373                       7   \n",
       "3                          9                0.845387                       9   \n",
       "4                          2                0.905016                       4   \n",
       "5                          5                0.891751                       8   \n",
       "6                          6                0.899683                       6   \n",
       "7                          4                0.900725                       5   \n",
       "8                          8                0.917057                       1   \n",
       "9                          3                0.905743                       3   \n",
       "\n",
       "   mean_test_f1_score  rank_test_f1_score  \n",
       "0            0.926109                   1  \n",
       "1            0.861997                  10  \n",
       "2            0.912438                   7  \n",
       "3            0.874004                   9  \n",
       "4            0.920090                   3  \n",
       "5            0.910690                   8  \n",
       "6            0.915225                   6  \n",
       "7            0.916334                   5  \n",
       "8            0.923947                   2  \n",
       "9            0.919298                   4  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results_30 = pd.DataFrame(adaboost_search_30.cv_results_)\n",
    "\n",
    "adaboost_results_30 = adaboost_results_30[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "                                           \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "                                           \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "adaboost_results_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME', 'n_estimators': 189}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_results_30[\"params\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12.744485139846802 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "adaboost_params_30 = {\"algorithm\":[\"SAMME\"],\n",
    "                      \"n_estimators\":[189]\n",
    "                     }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_adaboost_search_30 = GridSearchCV(adaboost,\n",
    "                                       adaboost_params_30,\n",
    "                                       n_jobs=-1,\n",
    "                                       cv=50,\n",
    "                                       scoring=scorers,\n",
    "                                       refit=False\n",
    "                                      )\n",
    "\n",
    "best_adaboost_search_30.fit(X_train_scaled_30, y_train_30)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_adaboost_30 = AdaBoostClassifier(algorithm=\"SAMME\", n_estimators=189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME', n_estimators=189)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_adaboost_30.fit(X_train_scaled_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost_30 = best_adaboost_30.predict(X_test_scaled_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24.18022394180298 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "RF_params_30 = {\"class_weight\":[\"balanced\"],\n",
    "                \"criterion\":[\"gini\"],\n",
    "                \"max_features\":[\"log2\"],\n",
    "                \"max_depth\":[12],\n",
    "                \"min_samples_split\":[25],\n",
    "                \"n_estimators\":[382]\n",
    "               }\n",
    "\n",
    "scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "           \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "           \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "          }\n",
    "\n",
    "best_RF_search_30 = GridSearchCV(RF,\n",
    "                                 RF_params_30,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=50,\n",
    "                                 scoring=scorers,\n",
    "                                 refit=False\n",
    "                                )\n",
    "\n",
    "best_RF_search_30.fit(X_train_scaled_30, y_train_30)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_RF_30 = RandomForestClassifier(class_weight=\"balanced\", criterion=\"gini\", max_features=\"log2\",\n",
    "                                 max_depth=12, min_samples_split=25, n_estimators=382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=12,\n",
       "                       max_features='log2', min_samples_split=25,\n",
       "                       n_estimators=382)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RF_30.fit(X_train_scaled_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF_30 = best_RF_30.predict(X_test_scaled_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New sample results VS Original ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.935897     0.980747   0.97384     0.958322      0.973552\n",
      "recall       0.898462     0.988242   0.97384     0.943352      0.973840\n",
      "f1-score     0.916797     0.984480   0.97384     0.950639      0.973623\n",
      "support    325.000000  1701.000000   0.97384  2026.000000   2026.000000\n",
      "\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.921212    0.987028  0.976308     0.954120      0.976438\n",
      "recall       0.932515    0.984706  0.976308     0.958611      0.976308\n",
      "f1-score     0.926829    0.985866  0.976308     0.956347      0.976366\n",
      "support    163.000000  850.000000  0.976308  1013.000000   1013.000000\n",
      "\n",
      "test_size=0.3:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.935412     0.973745  0.968082     0.954579      0.967590\n",
      "recall       0.860656     0.988632  0.968082     0.924644      0.968082\n",
      "f1-score     0.896478     0.981132  0.968082     0.938805      0.967538\n",
      "support    488.000000  2551.000000  0.968082  3039.000000   3039.000000\n",
      "\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893750     0.977140  0.963968     0.935445      0.963763\n",
      "recall       0.880000     0.980012  0.963968     0.930006      0.963968\n",
      "f1-score     0.886822     0.978574  0.963968     0.932698      0.963855\n",
      "support    325.000000  1701.000000  0.963968  2026.000000   2026.000000\n",
      "\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893750    0.976553  0.963475     0.935152      0.963230\n",
      "recall       0.877301    0.980000  0.963475     0.928650      0.963475\n",
      "f1-score     0.885449    0.978274  0.963475     0.931861      0.963337\n",
      "support    163.000000  850.000000  0.963475  1013.000000   1013.000000\n",
      "\n",
      "test_size=0.3:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.912736     0.961377   0.95459     0.937056      0.953566\n",
      "recall       0.793033     0.985496   0.95459     0.889264      0.954590\n",
      "f1-score     0.848684     0.973287   0.95459     0.910986      0.953278\n",
      "support    488.000000  2551.000000   0.95459  3039.000000   3039.000000\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.827778     0.983794  0.956071     0.905786      0.958766\n",
      "recall       0.916923     0.963551  0.956071     0.940237      0.956071\n",
      "f1-score     0.870073     0.973567  0.956071     0.921820      0.956965\n",
      "support    325.000000  1701.000000  0.956071  2026.000000   2026.000000\n",
      "\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.812834    0.986683   0.95459     0.899759      0.958709\n",
      "recall       0.932515    0.958824   0.95459     0.945669      0.954590\n",
      "f1-score     0.868571    0.972554   0.95459     0.920563      0.955822\n",
      "support    163.000000  850.000000   0.95459  1013.000000   1013.000000\n",
      "\n",
      "test_size=0.3:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.832692     0.978166  0.953274     0.905429      0.954806\n",
      "recall       0.887295     0.965896  0.953274     0.926595      0.953274\n",
      "f1-score     0.859127     0.971992  0.953274     0.915560      0.953868\n",
      "support    488.000000  2551.000000  0.953274  3039.000000   3039.000000\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\ntest_size=0.2:\\n{pd.DataFrame(classification_report(y_test, y_pred_gradient, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.1:\\n{pd.DataFrame(classification_report(y_test_10, y_pred_gradient_10, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.3:\\n{pd.DataFrame(classification_report(y_test_30, y_pred_gradient_30, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing AdaBoost\n",
    "print(f\"AdaBoost\\ntest_size=0.2:\\n{pd.DataFrame(classification_report(y_test, y_pred_adaboost, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.1:\\n{pd.DataFrame(classification_report(y_test_10, y_pred_adaboost_10, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.3:\\n{pd.DataFrame(classification_report(y_test_30, y_pred_adaboost_30, output_dict=True, target_names=['Churn', 'Customer']))}\\n\\n\\n\")\n",
    "\n",
    "# Comparing RandomForest\n",
    "print(f\"RandomForest\\ntest_size=0.2:\\n{pd.DataFrame(classification_report(y_test, y_pred_RF, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.1:\\n{pd.DataFrame(classification_report(y_test_10, y_pred_RF_10, output_dict=True, target_names=['Churn', 'Customer']))}\\n\")\n",
    "print(f\"test_size=0.3:\\n{pd.DataFrame(classification_report(y_test_30, y_pred_RF_30, output_dict=True, target_names=['Churn', 'Customer']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`test_size` reduced**\n",
    "\n",
    "Looking on the *Churn* customers, when the `test_size` is reduced, the **recall** improves and the **precision** goes worse. This doesn't happen on the *AdaBoost*, that's why I will be focusing on the other models.\n",
    "\n",
    "Looking into *RandomForest* and *GradientBoost* we can conclude that the best model is **GradientBoost**. The reason why is because the `recall` for the churned customers on both models is the same, but the `precision` drops significantly on the *RandomForest*. Also, important to mention that the overall metrics for the *Customers* are better on the *GradientBoost* too.\n",
    "\n",
    "* **`test_size` amplified**\n",
    "\n",
    "On the other hand, when we increase the `test_size`, the `recall` for the *Churn* customers goes down on the three models. Although in some cases the `precision` improves, the overall `f1_score` shows us that the results are worse with that sample, that's why we discard it.\n",
    "\n",
    "* **conclusions**\n",
    "\n",
    "As the results improve with less sample, is better to stay with a `test_size = 0.1` rather than a `0.2`. Also, it shows that the results are better for the **GradientBoost** model.\n",
    "\n",
    "We might consider keep reducing the sample to see if the numbers improve more, but that wouldn't be a good practice as with each sample reduction there would be less data for doing a good prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
