{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# ML classifier models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# resampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from collections import Counter\n",
    "\n",
    "# model selection (CV)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the DF into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Education_Level_encoded</th>\n",
       "      <th>Income_Category_encoded</th>\n",
       "      <th>Card_Category_encoded</th>\n",
       "      <th>x0_Married</th>\n",
       "      <th>x0_Single</th>\n",
       "      <th>x0_Unknown</th>\n",
       "      <th>x1_Existing Customer</th>\n",
       "      <th>x2_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>...</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>...</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_Age  Dependent_count  Months_on_book  Total_Relationship_Count  \\\n",
       "0            45                3              39                         5   \n",
       "1            49                5              44                         6   \n",
       "2            51                3              36                         4   \n",
       "3            40                4              34                         3   \n",
       "4            40                3              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                       1                      3       12691.0   \n",
       "1                       1                      2        8256.0   \n",
       "2                       1                      0        3418.0   \n",
       "3                       4                      1        3313.0   \n",
       "4                       1                      0        4716.0   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  ...  \\\n",
       "0                  777                 1.335             1144  ...   \n",
       "1                  864                 1.541             1291  ...   \n",
       "2                    0                 2.594             1887  ...   \n",
       "3                 2517                 1.405             1171  ...   \n",
       "4                    0                 2.175              816  ...   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Education_Level_encoded  \\\n",
       "0                1.625                  0.061                      2.0   \n",
       "1                3.714                  0.105                      4.0   \n",
       "2                2.333                  0.000                      4.0   \n",
       "3                2.333                  0.760                      2.0   \n",
       "4                2.500                  0.000                      1.0   \n",
       "\n",
       "   Income_Category_encoded  Card_Category_encoded  x0_Married  x0_Single  \\\n",
       "0                      3.0                    0.0         1.0        0.0   \n",
       "1                      1.0                    0.0         0.0        1.0   \n",
       "2                      4.0                    0.0         1.0        0.0   \n",
       "3                      1.0                    0.0         0.0        0.0   \n",
       "4                      3.0                    0.0         1.0        0.0   \n",
       "\n",
       "   x0_Unknown  x1_Existing Customer  x2_M  \n",
       "0         0.0                   1.0   1.0  \n",
       "1         0.0                   1.0   0.0  \n",
       "2         0.0                   1.0   1.0  \n",
       "3         1.0                   1.0   0.0  \n",
       "4         0.0                   1.0   1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_csv(\"../data/bank_processed_data.csv\", index_col=0)\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating X and y\n",
    "X = bank.drop(columns=\"x1_Existing Customer\")\n",
    "y = bank[\"x1_Existing Customer\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler() # initialize the scaler\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column that I want to identify is **x1_Existing Customer**, being **1** if the customer is still a customer, and **0** otherwise. In this case, as it's a True/False decission, the models that fit better for this type of Supervised ML are the Classifiers.\n",
    "\n",
    "I will start checking the different models, without parameter tuning, for identify which are the models that perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the models\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier()\n",
    "gradient = GradientBoostingClassifier()\n",
    "RF = RandomForestClassifier()\n",
    "adaboost = AdaBoostClassifier()\n",
    "extra_tree = ExtraTreesClassifier()\n",
    "support_vector = SVC()\n",
    "\n",
    "\n",
    "models = [neigh, tree, RF, adaboost, gradient, extra_tree, support_vector]\n",
    "model_names = [\"KNeighbors\", \"DecisionTree\", \"RandomForest\", \"AdaBoost\", \n",
    "               \"GradientBoost\", \"ExtraTress\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data per each category is not balanced, as customers represent 83.8% of the sample, the accuracy here is not relevant. \n",
    "\n",
    "In this scenario, I will focus more on `recall`, to ensure that the model classifies correctly the labels, and the precision. Mention that, the main focus will be on the label **0.0, as it is the customers that already churned the bank, and we want to focus on that part** to ensure that our model is able to predict possible future cases and act before churn happens.\n",
    "\n",
    "Last, but not least, `macro avg` will also be taken into consideration, as we want to ensure that **0.0** are classified correctly, but we want that the amount of **1.0** are good too. I would have to find the perfect balance between those metrics.\n",
    "\n",
    "*NOTES*\n",
    "\n",
    "The `precision` is the ratio TP / (TP + FP) where TP is the number of true positives and FP the number of false positives. The precision is intuitively **the ability of the classifier not to label as positive a sample that is negative**.\n",
    "\n",
    "The `recall` is the ratio TP / (TP + FN) where TP is the number of true positives and FN the number of false negatives. The recall is intuitively **the ability of the classifier to find all the positive samples**. Note that in binary classification, recall of the positive class is also known as `sensitivity`; recall of the negative class is `specificity`.\n",
    "\n",
    "The most important for this work is to increase the **sensitivity** (to detect all churn cases). Even though the other parameters are very important also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the best classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_classifier_model(models):\n",
    "    \"\"\"\n",
    "    Input: Models to test\n",
    "    Output: DF top 3 models\n",
    "    \"\"\"\n",
    "    # first batch of empty lists    \n",
    "    time_to_train = []\n",
    "    accuracy = []\n",
    "    macro_precision = []\n",
    "    macro_recall = []\n",
    "    macro_F1 = []\n",
    "    report_dict = []\n",
    "\n",
    "    for model in models:    \n",
    "        start = time.time()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        # metrics\n",
    "        accuracy_ = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        clasf_report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "        # appending to empty lists\n",
    "        time_to_train.append((time.time() - start))\n",
    "        accuracy.append(round(accuracy_,4))\n",
    "        macro_precision.append(round(precision,4))\n",
    "        macro_recall.append(round(recall,4))\n",
    "        macro_F1.append(round(f1,4))\n",
    "        report_dict.append(clasf_report_dict)\n",
    "    \n",
    "    # second batch\n",
    "    precision_0 = []\n",
    "    recall_0 = []\n",
    "    f1_0 = []\n",
    "    precision_1 = []\n",
    "    recall_1 = []\n",
    "    f1_1 = []\n",
    "\n",
    "    for report in report_dict:\n",
    "        # Info of churn label\n",
    "        precision_0.append(round(report[\"0.0\"][\"precision\"],4))\n",
    "        recall_0.append(round(report[\"0.0\"][\"recall\"],4))\n",
    "        f1_0.append(round(report[\"0.0\"][\"f1-score\"],4))\n",
    "\n",
    "        # Info of current customers\n",
    "        precision_1.append(round(report[\"1.0\"][\"precision\"],4))\n",
    "        recall_1.append(round(report[\"1.0\"][\"recall\"],4))\n",
    "        f1_1.append(round(report[\"1.0\"][\"f1-score\"],4))\n",
    "        \n",
    "    # creating DF\n",
    "    best_models_DF = pd.DataFrame({\"model\":model_names,\n",
    "                                   \"training_time\":time_to_train,\n",
    "                                   \"accuracy\":accuracy,\n",
    "                                   \"precision_macro\":macro_precision,\n",
    "                                   \"recall_macro\":macro_recall,\n",
    "                                   \"f1_macro\":macro_F1,\n",
    "                                   \"precision_0\":precision_0,\n",
    "                                   \"recall_0\":recall_0,\n",
    "                                   \"f1_0\":f1_0,\n",
    "                                   \"precision_1\":precision_1,\n",
    "                                   \"recall_1\":recall_1,\n",
    "                                   \"f1_1\":f1_1\n",
    "                                  })\n",
    "    \n",
    "    # getting top 3 models\n",
    "    top3 = best_models_DF.sort_values(by=[\"f1_macro\"], ascending=False).reset_index(drop=True).iloc[:3]\n",
    "    \n",
    "    return top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>training_time</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_0</th>\n",
       "      <th>recall_0</th>\n",
       "      <th>f1_0</th>\n",
       "      <th>precision_1</th>\n",
       "      <th>recall_1</th>\n",
       "      <th>f1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>1.612150</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>0.8864</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.9793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.427544</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.885127</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9062</td>\n",
       "      <td>0.9219</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.8677</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  training_time  accuracy  precision_macro  recall_macro  \\\n",
       "0  GradientBoost       1.612150    0.9650           0.9478        0.9194   \n",
       "1       AdaBoost       0.427544    0.9605           0.9332        0.9180   \n",
       "2   RandomForest       0.885127    0.9595           0.9398        0.9062   \n",
       "\n",
       "   f1_macro  precision_0  recall_0    f1_0  precision_1  recall_1    f1_1  \n",
       "0    0.9328       0.9233    0.8523  0.8864       0.9722    0.9865  0.9793  \n",
       "1    0.9254       0.8939    0.8554  0.8742       0.9726    0.9806  0.9766  \n",
       "2    0.9219       0.9119    0.8277  0.8677       0.9676    0.9847  0.9761  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_classifier_model(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three models that does the best selection for the churned customers and also for the actual customers are **GradientBoost**, **AdaBoost** and **RandomForest**.\n",
    "\n",
    "Now that we have in mind which models work best, let's start tuning them for improve their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "#                   \"criterion\":[\"friedman_mse\", \"mse\", \"mae\"],\n",
    "#                   \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#                   \"n_estimators\":randint(low=50, high=300),\n",
    "#                   \"max_depth\":randint(low=2, high=8),\n",
    "#                   \"max_leaf_nodes\":randint(low=5, high=15)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# gradient_search = RandomizedSearchCV(gradient,\n",
    "#                                      gradient_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=StratifiedKFold(),\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# gradient_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the results obtained, I will create a DF for visualize which are the scores for each scoring. After that, I will pick the parameters that performed better for passing it to GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_results = pd.DataFrame(gradient_search.cv_results_)\n",
    "\n",
    "# gradient_results = gradient_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                                      \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                                      \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# gradient_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_results[\"params\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we know which are the best parameters to pass to the model, we will create a function for each one of them and then obtain their respective **y_pred**. The **y_value** obtained will be stored in a variable for, later on, build the `classification_report` and `confusion_matrix`.\n",
    "\n",
    "The structure will be the same for future models and variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV\n",
    "    gradient_params = {\"loss\":[\"deviance\", \"exponential\"],\n",
    "                       \"criterion\":[\"friedman_mse\", \"mse\"],\n",
    "                       \"max_features\":[\"log2\",\"sqrt\"],\n",
    "                       \"n_estimators\":[260, 265, 270, 275, 280],\n",
    "                       \"max_depth\":[3, 4, 5],\n",
    "                       \"max_leaf_nodes\":[10, 12, 14, 16]\n",
    "                      }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_gradient = GridSearchCV(gradient,\n",
    "                                 gradient_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_gradient.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_gradient.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='sqrt', max_leaf_nodes=16,\n",
       "                           n_estimators=275)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_trainer(X_train, X_test, y_train, y_test, loss, criterion, max_features, n_estimators, max_depth, max_leaf_nodes):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the GradientBoostingClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_gradient \n",
    "    best_gradient = GradientBoostingClassifier(loss=loss, criterion=criterion,\n",
    "                                               max_features=max_features, n_estimators=n_estimators,\n",
    "                                               max_depth=max_depth, max_leaf_nodes=max_leaf_nodes\n",
    "                                              )\n",
    "    \n",
    "    # Model fit\n",
    "    best_gradient.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_gradient.predict(X_test)\n",
    "    \n",
    "    # Getting classification report\n",
    "    c_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    # Getting Kappa score\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, c_report, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gradient, classification_report_gradient, kappa_gradient = gradient_trainer(X_train_scaled,\n",
    "                                                                                   X_test_scaled,\n",
    "                                                                                   y_train,\n",
    "                                                                                   y_test,\n",
    "                                                                                   \"deviance\",\n",
    "                                                                                   \"friedman_mse\",\n",
    "                                                                                   \"log2\",\n",
    "                                                                                   265,\n",
    "                                                                                   5,\n",
    "                                                                                   14\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "#                   \"n_estimators\":randint(low=10, high=200)\n",
    "#                   }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# adaboost_search = RandomizedSearchCV(adaboost,\n",
    "#                                      adaboost_params,\n",
    "#                                      n_iter=10,\n",
    "#                                      n_jobs=-1,\n",
    "#                                      cv=10,\n",
    "#                                      scoring=scorers,\n",
    "#                                      refit=False,\n",
    "#                                      random_state=42\n",
    "#                                     )\n",
    "\n",
    "# adaboost_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost_results = pd.DataFrame(adaboost_search.cv_results_)\n",
    "\n",
    "# adaboost_results = adaboost_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                                      \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                                      \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# adaboost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost_results[\"params\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV\n",
    "    adaboost_params = {\"algorithm\":[\"SAMME\", \"SAMME.R\"],\n",
    "                       \"n_estimators\":[155, 158, 160, 161, 164]\n",
    "                      }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_adaboost = GridSearchCV(adaboost,\n",
    "                                 adaboost_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_adaboost.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=155)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_trainer(X_train, X_test, y_train, y_test, algorithm, n_estimators):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the AdaBoostClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_adaboost \n",
    "    best_adaboost = AdaBoostClassifier(algorithm=algorithm, n_estimators=n_estimators)\n",
    "    \n",
    "    # Model fit\n",
    "    best_adaboost.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_adaboost.predict(X_test)\n",
    "    \n",
    "    # Getting classification report\n",
    "    c_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    # Getting Kappa score\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, c_report, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adaboost, classification_report_adaboost, kappa_adaboost = adaboost_trainer(X_train_scaled,\n",
    "                                                                                   X_test_scaled,\n",
    "                                                                                   y_train,\n",
    "                                                                                   y_test,\n",
    "                                                                                   \"SAMME.R\",\n",
    "                                                                                   155\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "\n",
    "# RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "#              \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "#              \"class_weight\":[\"balanced\", \"balanced_subsample\"],          \n",
    "#              \"n_estimators\":randint(low=10, high=400),\n",
    "#              \"max_depth\":randint(low=2, high=20),\n",
    "#              \"min_samples_split\":randint(low=2, high=40)\n",
    "#             }\n",
    "\n",
    "# scorers = {\"precision_score\": make_scorer(precision_score, average=\"macro\"),\n",
    "#            \"recall_score\": make_scorer(recall_score, average=\"macro\"),\n",
    "#            \"f1_score\": make_scorer(f1_score, average=\"macro\")\n",
    "#           }\n",
    "\n",
    "# RF_search = RandomizedSearchCV(RF,\n",
    "#                                RF_params,\n",
    "#                                n_iter=10,\n",
    "#                                n_jobs=-1,\n",
    "#                                cv=50,\n",
    "#                                scoring=scorers,\n",
    "#                                refit=False,\n",
    "#                                random_state=42)\n",
    "\n",
    "# RF_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_results = pd.DataFrame(RF_search.cv_results_)\n",
    "\n",
    "# RF_results = RF_results[[\"params\", \"mean_test_precision_score\", \"rank_test_precision_score\",\n",
    "#                          \"mean_test_recall_score\", \"rank_test_recall_score\",\n",
    "#                          \"mean_test_f1_score\", \"rank_test_f1_score\"]]\n",
    "\n",
    "# RF_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_results[\"params\"][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_gridsearch(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Input: X_train and y_train for model training\n",
    "    Output: Best params\n",
    "    \n",
    "    \"\"\"\n",
    "    # Inputting the different parameters obtained from the RandomizedSearchCV    \n",
    "    RF_params = {\"criterion\":[\"gini\", \"entropy\"],\n",
    "                 \"max_features\":[\"auto\", \"sqrt\", \"log2\"],\n",
    "                 \"class_weight\":[\"balanced\", \"balanced_subsample\"],               \n",
    "                 \"n_estimators\":[390, 395, 400, 405],\n",
    "                 \"max_depth\":[8, 10, 12],\n",
    "                 \"min_samples_split\":[16, 18, 20, 22]\n",
    "                }\n",
    "\n",
    "    # Running the best_gradient with GridSearchCV\n",
    "    best_RF = GridSearchCV(RF,\n",
    "                                 RF_params,\n",
    "                                 n_jobs=-1,\n",
    "                                 cv=StratifiedKFold(),\n",
    "                                 scoring=\"f1_macro\"\n",
    "                                )\n",
    "    \n",
    "    best_RF.fit(X_train, y_train)\n",
    "    \n",
    "    best = best_RF.best_estimator_\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=12, min_samples_split=18, n_estimators=390)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_gridsearch(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_trainer(X_train, X_test, y_train, y_test, class_weight, criterion, max_features, max_depth, min_samples_split, n_estimators):\n",
    "    \"\"\"\n",
    "    Input: All the inputs for training the RandomForestClassifier with GridSearchCV\n",
    "    Output: y_pred\n",
    "    \"\"\"\n",
    "    # Creating the best_RF\n",
    "    best_RF = RandomForestClassifier(class_weight=class_weight, criterion=criterion, max_features=max_features,\n",
    "                                     max_depth=max_depth, min_samples_split=min_samples_split, n_estimators=n_estimators)\n",
    "    \n",
    "    # Model fit\n",
    "    best_RF.fit(X_train, y_train)\n",
    "    \n",
    "    # Model train\n",
    "    y_pred = best_RF.predict(X_test)\n",
    "    \n",
    "    # Getting classification report\n",
    "    c_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    # Getting Kappa score\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, c_report, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF, classification_report_RF, kappa_RF = RF_trainer(X_train_scaled,\n",
    "                                                           X_test_scaled,\n",
    "                                                           y_train,\n",
    "                                                           y_test,\n",
    "                                                           \"balanced\",\n",
    "                                                           \"entropy\",\n",
    "                                                           \"auto\",\n",
    "                                                           12,\n",
    "                                                           18,\n",
    "                                                           390\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_predictions(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Input: Variables for training a model\n",
    "    Output: y_pred for three different models    \n",
    "    \"\"\"\n",
    "    # GradientBoost\n",
    "    gradient.fit(X_train, y_train)\n",
    "    y_pred_initial_gradient = gradient.predict(X_test)\n",
    "    \n",
    "    # AdaBoost\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    y_pred_initial_adaboost = adaboost.predict(X_test)\n",
    "    \n",
    "    # RF\n",
    "    RF.fit(X_train, y_train)\n",
    "    y_pred_initial_RF = RF.predict(X_test)\n",
    "    \n",
    "    return y_pred_initial_gradient, y_pred_initial_adaboost, y_pred_initial_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_initial_gradient, y_pred_initial_adaboost, y_pred_initial_RF = initial_predictions(X_train_scaled, \n",
    "                                                                                          y_train, \n",
    "                                                                                          X_test_scaled\n",
    "                                                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_class_reports(y_test, y_pred1, y_pred2, y_pred3):\n",
    "    \"\"\"\n",
    "    Input: Three y_pred variables of the different models\n",
    "    Output: Classification reports of the models    \n",
    "    \"\"\"\n",
    "    # GradientBoost\n",
    "    initial_classification_gradient = pd.DataFrame(classification_report(y_test, y_pred1, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    # AdaBoost\n",
    "    initial_classification_adaboost = pd.DataFrame(classification_report(y_test, y_pred2, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    # RF\n",
    "    initial_classification_RF = pd.DataFrame(classification_report(y_test, y_pred3, output_dict=True, target_names=['Churn', 'Customer']))\n",
    "    \n",
    "    return initial_classification_gradient, initial_classification_adaboost, initial_classification_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_class_gradient, first_class_adaboost, first_class_RF = initial_class_reports(y_test,\n",
    "                                                                                  y_pred_initial_gradient,\n",
    "                                                                                  y_pred_initial_adaboost,\n",
    "                                                                                  y_pred_initial_RF\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.923333     0.972190  0.964956     0.947762      0.964353\n",
      "recall       0.852308     0.986479  0.964956     0.919393      0.964956\n",
      "f1-score     0.886400     0.979282  0.964956     0.932841      0.964383\n",
      "support    325.000000  1701.000000  0.964956  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.936306     0.981893  0.974827     0.959099      0.974580\n",
      "recall       0.904615     0.988242  0.974827     0.946429      0.974827\n",
      "f1-score     0.920188     0.985057  0.974827     0.952622      0.974651\n",
      "support    325.000000  1701.000000  0.974827  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.893891     0.972595  0.960513     0.933243      0.959969\n",
      "recall       0.855385     0.980600  0.960513     0.917992      0.960513\n",
      "f1-score     0.874214     0.976581  0.960513     0.925397      0.960160\n",
      "support    325.000000  1701.000000  0.960513  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.897196     0.978299  0.965449     0.937748      0.965289\n",
      "recall       0.886154     0.980600  0.965449     0.933377      0.965449\n",
      "f1-score     0.891641     0.979448  0.965449     0.935544      0.965362\n",
      "support    325.000000  1701.000000  0.965449  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Initial:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.916388     0.970469  0.962488     0.943428      0.961794\n",
      "recall       0.843077     0.985303  0.962488     0.914190      0.962488\n",
      "f1-score     0.878205     0.977830  0.962488     0.928017      0.961848\n",
      "support    325.000000  1701.000000  0.962488  2026.000000   2026.000000\n",
      "\n",
      "Modified:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.845272     0.982111  0.958539     0.913692      0.960160\n",
      "recall       0.907692     0.968254  0.958539     0.937973      0.958539\n",
      "f1-score     0.875371     0.975133  0.958539     0.925252      0.959130\n",
      "support    325.000000  1701.000000  0.958539  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "GradientBoost Kappa: 0.9053\n",
      "AdaBoost Kappa: 0.8711\n",
      "RF Kappa: 0.8505\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\nInitial:\\n{first_class_gradient}\\n\")\n",
    "print(f\"Modified:\\n{classification_report_gradient}\\n\\n\")\n",
    "\n",
    "# Comparing AdaBoost\n",
    "print(f\"AdaBoost\\nInitial:\\n{first_class_adaboost}\\n\")\n",
    "print(f\"Modified:\\n{classification_report_adaboost}\\n\\n\")\n",
    "\n",
    "# Comparing RandomForest\n",
    "print(f\"RandomForest\\nInitial:\\n{first_class_RF}\\n\")\n",
    "print(f\"Modified:\\n{classification_report_RF}\\n\\n\")\n",
    "\n",
    "# Looking Kappa\n",
    "print(f\"GradientBoost Kappa: {round(kappa_gradient,4)}\")\n",
    "print(f\"AdaBoost Kappa: {round(kappa_adaboost,4)}\")\n",
    "print(f\"RF Kappa: {round(kappa_RF,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the `classification_report`, we will focus on the **Churn** column. On a first view, we can identify that the best models are the `GradientBoost` and `RandomForest`. Let's dive deep and compare each other:\n",
    "1. **`GradientBoost`**: The `precision` is 0.9363, the `recall` is 0.9046, the `f1-score` is 0.9201 and the `accuracy` is 0.9748.\n",
    "2. **`RandomForest`**: The `precision` is 0.8468, the `recall` is 0.9015, the `f1-score` is 0.8733 and the `accuracy` is 0.9580.\n",
    "\n",
    "Although the `recall` is slightly higher on the `RandomForest`, the precision has a big difference compared to the `GradientBoost`. Also, taking into consideration that the `f1-score` will give us a more accurate reference of which model performs better with a more conservative approach, we can ensure that the **`GradientBoost`** is the best model overall.\n",
    "\n",
    "We can also notice that the **Customer** column is much better on the `GradientBoost` rather than on the `RandomForest`, and, lastly, there is a considerable difference of `cohen_kappa_score` between both models.\n",
    "\n",
    "For further testing, we will only focus with **`GradientBoost`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already did our initial `RandomizedSearchCV` for obtaining the values were we should focus with the `GridSearchCV`, in this case is not neccesary to do that step again.\n",
    "\n",
    "What we will do, is the following:\n",
    "* Split the test size in two different values, **0.1** and **0.3**.\n",
    "* Obtain the best parameters for the gridsearch and see if they are slightly different from the previous model.\n",
    "* Train the models with the new samples.\n",
    "* Compare the new `classification_report` with the previous one and see if there is improvement. **In case that the model improves, for further analysis we will use the best one**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_10, X_test_10, y_train_10, y_test_10 = train_test_split(X, y, test_size = 0.1, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_10 = scaler.fit_transform(X_train_10)\n",
    "X_test_scaled_10 = scaler.transform(X_test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, max_features='sqrt', max_leaf_nodes=16,\n",
       "                           n_estimators=270)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_10, y_train_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_10, class_report_gradient_10, kappa_gradient_10 = gradient_trainer(X_train_scaled_10,\n",
    "                                                                                   X_test_scaled_10,\n",
    "                                                                                   y_train_10,\n",
    "                                                                                   y_test_10,\n",
    "                                                                                   \"deviance\",\n",
    "                                                                                   \"mse\",\n",
    "                                                                                   \"sqrt\",\n",
    "                                                                                   265,\n",
    "                                                                                   5,\n",
    "                                                                                   16\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30% Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30, X_test_30, y_train_30, y_test_30 = train_test_split(X, y, test_size = 0.3, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_30 = scaler.fit_transform(X_train_30)\n",
    "X_test_scaled_30 = scaler.transform(X_test_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', max_depth=4, max_features='sqrt',\n",
       "                           max_leaf_nodes=14, n_estimators=265)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_30, y_train_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_30, class_report_gradient_30, kappa_gradient_30 = gradient_trainer(X_train_scaled_30,\n",
    "                                                                                   X_test_scaled_30,\n",
    "                                                                                   y_train_30,\n",
    "                                                                                   y_test_30,\n",
    "                                                                                   \"deviance\",\n",
    "                                                                                   \"mse\",\n",
    "                                                                                   \"sqrt\",\n",
    "                                                                                   265,\n",
    "                                                                                   4,\n",
    "                                                                                   14\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New sample results VS Previous sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.936306     0.981893  0.974827     0.959099      0.974580\n",
      "recall       0.904615     0.988242  0.974827     0.946429      0.974827\n",
      "f1-score     0.920188     0.985057  0.974827     0.952622      0.974651\n",
      "support    325.000000  1701.000000  0.974827  2026.000000   2026.000000\n",
      "\n",
      "test_size=0.1:\n",
      "                Churn    Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.908537    0.983510  0.971372     0.946023      0.971446\n",
      "recall       0.914110    0.982353  0.971372     0.948232      0.971372\n",
      "f1-score     0.911315    0.982931  0.971372     0.947123      0.971408\n",
      "support    163.000000  850.000000  0.971372  1013.000000   1013.000000\n",
      "\n",
      "test_size=0.3:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.936404     0.976384  0.970385     0.956394      0.969964\n",
      "recall       0.875000     0.988632  0.970385     0.931816      0.970385\n",
      "f1-score     0.904661     0.982470  0.970385     0.943565      0.969975\n",
      "support    488.000000  2551.000000  0.970385  3039.000000   3039.000000\n",
      "\n",
      "\n",
      "test_size=0.2 Kappa: 0.9053\n",
      "test_size=0.1 Kappa: 0.8942\n",
      "test_size=0.3 Kappa: 0.8872\n"
     ]
    }
   ],
   "source": [
    "# Comparing GradientBoost\n",
    "print(f\"GradientBoost\\ntest_size=0.2:\\n{classification_report_gradient}\\n\")\n",
    "print(f\"test_size=0.1:\\n{class_report_gradient_10}\\n\")\n",
    "print(f\"test_size=0.3:\\n{class_report_gradient_30}\\n\\n\")\n",
    "\n",
    "print(f\"test_size=0.2 Kappa: {round(kappa_gradient,4)}\")\n",
    "print(f\"test_size=0.1 Kappa: {round(kappa_gradient_10,4)}\")\n",
    "print(f\"test_size=0.3 Kappa: {round(kappa_gradient_30,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`test_size` reduced**\n",
    "\n",
    "Looking on the *Churn* customers, when the `test_size` is reduced, the `recall` improves and the `precision` goes worse.\n",
    "\n",
    "The `recall` for the churned customers improved considerable, above the 0.9, and although that the overall accuracy dropped a little bit, the `f1-score` increased, which offers a more stable model.\n",
    "\n",
    "\n",
    "* **`test_size` amplified**\n",
    "\n",
    "When we increase the `test_size`, the `recall` for the *Churn* customers goes down, but same happens with the `precision` and, per se, with the `f1-score`. We can conclude that, when the sample increases, results go worse.\n",
    "\n",
    "\n",
    "* **conclusions**\n",
    "\n",
    "For the conclusions, as we discussed that, in some aspects, a reduced `test_size` improved certain parts of the model, it also happens that others drop. But here are the main aspects why **`test_size=0.2`** is better:\n",
    "1. The percentage of `recall` is slightly worse than on the `test_size=0.1`, but the `precision` is far better..\n",
    "2. The overall `f1-score` is higher and the `accuracy` too.\n",
    "3. `cohen_kappa_score` shows better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the measures take into consideration the `macro avg` instead of the `weighted avg`, it would be a good idea to see how the models performs with **resampling**. In this case, there will be two kind of resamples:\n",
    "\n",
    "1. **Over Sampling**: Fake data will be created for the train set using the `SMOTE` method, increasing the size of the minority class as maximum as possible.\n",
    "2. **Under Sampling**: Original data will be removed for the train set using `NearMiss` method, reducing the majority class to the same amount as the minority."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({1.0: 6799, 0.0: 1302})\n",
      "Resample dataset shape: Counter({0.0: 6799, 1.0: 6799})\n"
     ]
    }
   ],
   "source": [
    "# initializing SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking that the amount is the same for each value\n",
    "\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_smote = scaler.fit_transform(X_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=4, max_features='sqrt',\n",
       "                           max_leaf_nodes=16, n_estimators=280)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_smote, class_report_gradient_smote, kappa_gradient_smote = gradient_trainer(X_train_scaled_smote,\n",
    "                                                                                            X_test_scaled,\n",
    "                                                                                            y_train_smote,\n",
    "                                                                                            y_test,\n",
    "                                                                                            \"exponential\",\n",
    "                                                                                            \"friedman_mse\",\n",
    "                                                                                            \"sqrt\",\n",
    "                                                                                            280,\n",
    "                                                                                            4,\n",
    "                                                                                            16\n",
    "                                                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({1.0: 6799, 0.0: 1302})\n",
      "Resample dataset shape: Counter({0.0: 1302, 1.0: 1302})\n"
     ]
    }
   ],
   "source": [
    "# initializing NearMiss\n",
    "\n",
    "nm = NearMiss()\n",
    "\n",
    "X_train_nm, y_train_nm = nm.fit_resample(X_train, y_train)\n",
    "\n",
    "# checking that the amount is the same for each value\n",
    "\n",
    "print('Original dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_train_nm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "X_train_scaled_nm = scaler.fit_transform(X_train_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='mse', max_depth=5, max_features='sqrt',\n",
       "                           max_leaf_nodes=16, n_estimators=265)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining best params\n",
    "gradient_gridsearch(X_train_scaled_nm, y_train_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing y_pred\n",
    "y_pred_gradient_nm, class_report_gradient_nm, kappa_gradient_nm = gradient_trainer(X_train_scaled_nm,\n",
    "                                                                                   X_test_scaled,\n",
    "                                                                                   y_train_nm,\n",
    "                                                                                   y_test,\n",
    "                                                                                   \"deviance\",\n",
    "                                                                                   \"mse\",\n",
    "                                                                                   \"sqrt\",\n",
    "                                                                                   265,\n",
    "                                                                                   5,\n",
    "                                                                                   16\n",
    "                                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "test_size=0.2:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.936306     0.981893  0.974827     0.959099      0.974580\n",
      "recall       0.904615     0.988242  0.974827     0.946429      0.974827\n",
      "f1-score     0.920188     0.985057  0.974827     0.952622      0.974651\n",
      "support    325.000000  1701.000000  0.974827  2026.000000   2026.000000\n",
      "\n",
      "Over Sampling:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.249616     1.000000  0.517769     0.624808      0.879627\n",
      "recall       1.000000     0.425632  0.517769     0.712816      0.517769\n",
      "f1-score     0.399508     0.597113  0.517769     0.498311      0.565415\n",
      "support    325.000000  1701.000000  0.517769  2026.000000   2026.000000\n",
      "\n",
      "Under Sampling:\n",
      "                Churn     Customer  accuracy    macro avg  weighted avg\n",
      "precision    0.281385     0.941016  0.640178     0.611201      0.835202\n",
      "recall       0.800000     0.609641  0.640178     0.704821      0.640178\n",
      "f1-score     0.416333     0.739922  0.640178     0.578127      0.688013\n",
      "support    325.000000  1701.000000  0.640178  2026.000000   2026.000000\n",
      "\n",
      "\n",
      "test_size=0.2 Kappa: 0.9053\n",
      "Over Sampling Kappa: 0.1921\n",
      "Under Sampling Kappa: 0.2347\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(f\"GradientBoost\\ntest_size=0.2:\\n{classification_report_gradient}\\n\")\n",
    "print(f\"Over Sampling:\\n{class_report_gradient_smote}\\n\")\n",
    "print(f\"Under Sampling:\\n{class_report_gradient_nm}\\n\\n\")\n",
    "\n",
    "print(f\"test_size=0.2 Kappa: {round(kappa_gradient,4)}\")\n",
    "print(f\"Over Sampling Kappa: {round(kappa_gradient_smote,4)}\")\n",
    "print(f\"Under Sampling Kappa: {round(kappa_gradient_nm,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking the different results, we can conclude that neither **Over Sampling** or **Under Sampling** provides better results (or barely similar) to the previous ones. \n",
    "\n",
    "Although the `recall` for the *Churn* customers is perfect with the over sampling, the rest of variables are really bad, causing that the model has a very low `accuracy` and an even lower `cohen_kappa_score`.\n",
    "\n",
    "On the other hand, the under sampling lowered the values mentioned on the previous paragraph, but not as aggresively as the over sampling does. Although, the model is still pretty bad and we will not consider it.\n",
    "\n",
    "Last, but not least, we remain with the **GradientBoost | test_size = 0.2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassified Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ending the project, I would like to compare the amount of misclassified values from the `y_pred_gradient` compared with the correct output that might had.\n",
    "\n",
    "First, let's compare the results from `y_pred_gradient` to `y_test` and, if they don't match, will append their index to an empty list for further exploration on the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_copy = np.asarray(y_test)\n",
    "\n",
    "misclassified = []\n",
    "\n",
    "for i in range(len(y_test_copy)):\n",
    "    if y_test_copy[i] != y_pred_gradient[i]:\n",
    "        misclassified.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of the original DF\n",
    "bank_misclassified = bank.copy()\n",
    "\n",
    "# Filtering only for the index misclassified\n",
    "bank_misclassified = bank_misclassified.iloc[misclassified, :]\n",
    "\n",
    "# Creating a new column with the wrong classification the model gave to that index\n",
    "bank_misclassified.loc[:, \"Classified_As\"] = np.where(bank_misclassified[\"x1_Existing Customer\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many values were misclassified per each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46\n",
       "1     5\n",
       "Name: Classified_As, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_misclassified.Classified_As.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into that, we can see that more than 90% of the misclassifications are due to setting them as **churned customer**. Let's compare those misclassified customers with correct churned customers and try to find out why the model put them on the wrong batch.\n",
    "\n",
    "For that case, although all columns are numerical, we will try to focus with the original numerical columns, not the encoded ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrong *Churned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Churned Anallysis\n",
    "wrong_churned = bank_misclassified[bank_misclassified.Classified_As != 1]\n",
    "correct_churned = bank.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Churned when customer\n",
    "wrong_churned = wrong_churned.iloc[:, :13].describe()\n",
    "wrong_churned = wrong_churned.loc[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct churned\n",
    "correct_churned = correct_churned[correct_churned[\"x1_Existing Customer\"] == 0].iloc[:, :13].describe()\n",
    "correct_churned = correct_churned.loc[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_churn = []\n",
    "\n",
    "for i in zip(wrong_churned, correct_churned):\n",
    "    values_churn.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_churn = [list(element) for element in values_churn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[46.23913043478261, 46.659496004917024],\n",
       " [2.369565217391304, 2.402581438229871],\n",
       " [34.78260869565217, 36.178242163491085],\n",
       " [4.630434782608695, 3.279655808236017],\n",
       " [2.152173913043478, 2.693300553165335],\n",
       " [2.391304347826087, 2.972341733251383],\n",
       " [8218.695652173914, 8136.03945912722],\n",
       " [1294.1521739130435, 672.8229870928088],\n",
       " [0.8408260869565218, 0.6942765826674863],\n",
       " [1681.4130434782608, 3095.025814382299],\n",
       " [41.0, 44.93362015980332],\n",
       " [0.7752608695652173, 0.5543859864781803],\n",
       " [0.3121521739130435, 0.16247510755992617]]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_Age                  46.659496\n",
       "Dependent_count                2.402581\n",
       "Months_on_book                36.178242\n",
       "Total_Relationship_Count       3.279656\n",
       "Months_Inactive_12_mon         2.693301\n",
       "Contacts_Count_12_mon          2.972342\n",
       "Credit_Limit                8136.039459\n",
       "Total_Revolving_Bal          672.822987\n",
       "Total_Amt_Chng_Q4_Q1           0.694277\n",
       "Total_Trans_Amt             3095.025814\n",
       "Total_Trans_Ct                44.933620\n",
       "Total_Ct_Chng_Q4_Q1            0.554386\n",
       "Avg_Utilization_Ratio          0.162475\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_churn[2])\n",
    "\n",
    "plt.xlabel(\"Months on the Bank\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/months_bank_churn.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_churn[-3])\n",
    "\n",
    "plt.xlabel(\"Total Transactions (Count)\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/transactions_count_churn.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_churn[-1])\n",
    "\n",
    "plt.xlabel(\"Avg. Card Utilization Ratio\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/card_utilization_rate_churn.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrong *Customer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Customer Analysis\n",
    "wrong_customer = bank_misclassified[bank_misclassified.Classified_As != 0]\n",
    "correct_customer = bank.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customer when churned\n",
    "wrong_customer = wrong_customer.iloc[:, :13].describe()\n",
    "wrong_customer = wrong_customer.loc[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct customers\n",
    "correct_customer = correct_customer[correct_customer[\"x1_Existing Customer\"] == 1].iloc[:, :13].describe()\n",
    "correct_customer = correct_customer.loc[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_customer = []\n",
    "\n",
    "for i in zip(wrong_customer, correct_customer):\n",
    "    values_customer.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_customer = [list(element) for element in values_customer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_customer[2], color=\"darkorange\")\n",
    "\n",
    "plt.xlabel(\"Months on the Bank\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/months_bank_customer.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_customer[-3], color=\"darkorange\")\n",
    "\n",
    "plt.xlabel(\"Total Transactions (Count)\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/transactions_count_customer.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=values_customer[-1], color=\"darkorange\")\n",
    "\n",
    "plt.xlabel(\"Avg. Card Utilization Ratio\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../images/card_utilization_rate_customer.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
